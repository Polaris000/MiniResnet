{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":8020904,"sourceType":"datasetVersion","datasetId":4726359},{"sourceId":8031089,"sourceType":"datasetVersion","datasetId":4733697}],"dockerImageVersionId":30674,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install torchsummary","metadata":{"execution":{"iopub.status.busy":"2024-04-11T23:47:21.813832Z","iopub.execute_input":"2024-04-11T23:47:21.816742Z","iopub.status.idle":"2024-04-11T23:47:36.221073Z","shell.execute_reply.started":"2024-04-11T23:47:21.816709Z","shell.execute_reply":"2024-04-11T23:47:36.220169Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"Collecting torchsummary\n  Downloading torchsummary-1.5.1-py3-none-any.whl.metadata (296 bytes)\nDownloading torchsummary-1.5.1-py3-none-any.whl (2.8 kB)\nInstalling collected packages: torchsummary\nSuccessfully installed torchsummary-1.5.1\n","output_type":"stream"}]},{"cell_type":"code","source":"import torch\nimport torchvision.transforms as transforms\nfrom torchvision import datasets\nimport pickle\nfrom PIL import Image\nimport torchsummary\nimport warnings\nimport os\nimport pandas as pd\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\n\n","metadata":{"execution":{"iopub.status.busy":"2024-04-11T23:51:11.902439Z","iopub.execute_input":"2024-04-11T23:51:11.903130Z","iopub.status.idle":"2024-04-11T23:51:20.615729Z","shell.execute_reply.started":"2024-04-11T23:51:11.903095Z","shell.execute_reply":"2024-04-11T23:51:20.614929Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":"## Load the data","metadata":{}},{"cell_type":"code","source":"class TestData(torch.utils.data.Dataset):\n    def __init__(self, file_path, transform=None):\n        self.data = None\n        with open(file_path, \"rb\") as f:\n            self.data = pickle.load(f)\n            self.images = self.data[b\"data\"]\n            self.ids = self.data[b\"ids\"]\n        self.transform = transform\n\n    def __len__(self):\n        return len(self.ids)\n\n    def __getitem__(self, index):\n        img = self.images[index]\n        id_ = self.ids[index]\n\n        # Convert image to PIL Image\n        img = img.reshape(3, 32, 32).transpose(1, 2, 0)\n        img = Image.fromarray(img)\n\n        if self.transform is not None:\n            img = self.transform(img)\n\n        return id_, img\n","metadata":{"execution":{"iopub.status.busy":"2024-04-11T23:52:50.971547Z","iopub.execute_input":"2024-04-11T23:52:50.972527Z","iopub.status.idle":"2024-04-11T23:52:50.981037Z","shell.execute_reply.started":"2024-04-11T23:52:50.972482Z","shell.execute_reply":"2024-04-11T23:52:50.979999Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"def augment_data(input_dim=(3, 32, 32)):\n    transform_train = transforms.Compose(\n        [\n            transforms.RandomHorizontalFlip(),\n            transforms.ColorJitter(\n                brightness=0.1, contrast=0.1, saturation=0.1, hue=0.1\n            ),\n            transforms.RandomCrop(input_dim[1], padding=4),\n            transforms.RandomAffine(degrees=10, translate=(0.1, 0.1), shear=15),\n            transforms.RandomAdjustSharpness(4.5, p=0.5),\n            transforms.ToTensor(),\n            transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n        ]\n    )\n\n    transform_val = transforms.Compose(\n        [\n            transforms.RandomAdjustSharpness(4.5, p=0.5),\n            transforms.ToTensor(),\n            transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n        ]\n    )\n    \n    transform_test = transforms.Compose(\n        [\n            transforms.RandomAdjustSharpness(4.5, p=0.5),\n            transforms.ToTensor(),\n            transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n        ]\n    )\n    return transform_train, transform_val, transform_test","metadata":{"execution":{"iopub.status.busy":"2024-04-11T23:52:51.390014Z","iopub.execute_input":"2024-04-11T23:52:51.390386Z","iopub.status.idle":"2024-04-11T23:52:51.399419Z","shell.execute_reply.started":"2024-04-11T23:52:51.390362Z","shell.execute_reply":"2024-04-11T23:52:51.398453Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"# def load_data(input_dim=(3, 32, 32)):\n#     import os\n\n#     data_directory = os.path.dirname(__file__) + \"/../data\"\n#     test_path = os.path.join(data_directory, \"testdata\", \"cifar_test_nolabels.pkl\")\ndata_directory = \"./data\"\ninput_dim = (3,32,32)\n#test_path = \"/kaggle/input/test-set/cifar_test_nolabels.pkl\"\ntest_path = \"/kaggle/input/test-data/cifar_test_nolabels.pkl\"\n\ntransform_train, transform_val, transform_test = augment_data(input_dim)\n\ntrainset = datasets.CIFAR10(\n    root=data_directory, train=True, download=True, transform=transform_train\n)\ntrainloader = torch.utils.data.DataLoader(\n    trainset, batch_size=128, shuffle=True, num_workers=2\n)\n\nval_set = datasets.CIFAR10(\n    root=data_directory, train=False, download=True, transform=transform_val\n)\nval_loader = torch.utils.data.DataLoader(\n    val_set, batch_size=100, shuffle=False, num_workers=2\n)\n\ntest_set = TestData(file_path=test_path, transform=transform_test)\ntestloader = torch.utils.data.DataLoader(\n    test_set, batch_size=1, shuffle=False, num_workers=2\n)\n\nclasses = (\n    \"plane\",\n    \"car\",\n    \"bird\",\n    \"cat\",\n    \"deer\",\n    \"dog\",\n    \"frog\",\n    \"horse\",\n    \"ship\",\n    \"truck\",\n)\n\n#     return trainloader, val_loader, testloader, classes\n","metadata":{"execution":{"iopub.status.busy":"2024-04-11T23:52:51.823720Z","iopub.execute_input":"2024-04-11T23:52:51.824128Z","iopub.status.idle":"2024-04-11T23:52:58.638688Z","shell.execute_reply.started":"2024-04-11T23:52:51.824100Z","shell.execute_reply":"2024-04-11T23:52:58.637920Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 170498071/170498071 [00:02<00:00, 76828193.27it/s]\n","output_type":"stream"},{"name":"stdout","text":"Extracting ./data/cifar-10-python.tar.gz to ./data\nFiles already downloaded and verified\n","output_type":"stream"}]},{"cell_type":"code","source":"# for batch_idx, samples in enumerate(val_loader):\n#       print(batch_idx, samples)","metadata":{"_kg_hide-output":true,"_kg_hide-input":true,"scrolled":true,"execution":{"iopub.status.busy":"2024-04-11T23:52:58.640306Z","iopub.execute_input":"2024-04-11T23:52:58.640601Z","iopub.status.idle":"2024-04-11T23:52:58.644852Z","shell.execute_reply.started":"2024-04-11T23:52:58.640571Z","shell.execute_reply":"2024-04-11T23:52:58.643839Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"# for batch_idx, samples in enumerate(val_loader):\n# #       print(batch_idx, samples)","metadata":{"execution":{"iopub.status.busy":"2024-04-11T23:52:58.645882Z","iopub.execute_input":"2024-04-11T23:52:58.646128Z","iopub.status.idle":"2024-04-11T23:52:58.655359Z","shell.execute_reply.started":"2024-04-11T23:52:58.646108Z","shell.execute_reply":"2024-04-11T23:52:58.654569Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":"# define model","metadata":{}},{"cell_type":"code","source":"class ResidualBlock(nn.Module):\n    expansion = 1\n\n    def __init__(self, in_planes, planes, stride=1):\n        super(ResidualBlock, self).__init__()\n        self.conv1 = nn.Conv2d(\n            in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False\n        )\n        self.bn1 = nn.BatchNorm2d(planes)\n        self.conv2 = nn.Conv2d(\n            planes, planes, kernel_size=3, stride=1, padding=1, bias=False\n        )\n        self.bn2 = nn.BatchNorm2d(planes)\n\n        self.shortcut = nn.Sequential()\n        if stride != 1 or in_planes != self.expansion * planes:\n            self.shortcut = nn.Sequential(\n                nn.Conv2d(\n                    in_planes,\n                    self.expansion * planes,\n                    kernel_size=1,\n                    stride=stride,\n                    bias=False,\n                ),\n                nn.BatchNorm2d(self.expansion * planes),\n            )\n\n    def forward(self, x):\n        out = F.relu(self.bn1(self.conv1(x)))\n        out = self.bn2(self.conv2(out))\n        out += self.shortcut(x)\n        out = F.relu(out)\n        return out","metadata":{"execution":{"iopub.status.busy":"2024-04-12T02:18:31.192089Z","iopub.execute_input":"2024-04-12T02:18:31.192465Z","iopub.status.idle":"2024-04-12T02:18:31.203427Z","shell.execute_reply.started":"2024-04-12T02:18:31.192435Z","shell.execute_reply":"2024-04-12T02:18:31.202145Z"},"trusted":true},"execution_count":38,"outputs":[]},{"cell_type":"code","source":"class MiniResNet(nn.Module):\n    def __init__(self, num_blocks=(2, 2, 2, 2)):\n        super(MiniResNet, self).__init__()\n        self.in_planes = 64\n\n        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\n        self.bn1 = nn.BatchNorm2d(64)\n        self.layer1 = self._make_layer(64, num_blocks[0], stride=1)\n        self.layer2 = self._make_layer(128, num_blocks[1], stride=2)\n        self.layer3 = self._make_layer(256, num_blocks[2], stride=2)\n        self.layer4 = self._make_layer(512, num_blocks[3], stride=2)\n        self.linear = nn.Linear(512, 10)\n#         self.linear = nn.Linear(256, 10)\n\n    def _make_layer(self, planes, num_blocks, stride):\n        strides = [stride] + [1] * (num_blocks - 1)\n        layers = []\n        for stride in strides:\n            layers.append(ResidualBlock(self.in_planes, planes, stride))\n            self.in_planes = planes\n        return nn.Sequential(*layers)\n\n    def forward(self, x):\n        out = F.relu(self.bn1(self.conv1(x)))\n        out = self.layer1(out)\n        out = self.layer2(out)\n        out = self.layer3(out)\n        out = self.layer4(out)\n        out = F.max_pool2d(out, 4)\n        out = out.view(out.size(0), -1)\n        out = self.linear(out)\n        return out","metadata":{"execution":{"iopub.status.busy":"2024-04-12T02:18:31.711022Z","iopub.execute_input":"2024-04-12T02:18:31.711406Z","iopub.status.idle":"2024-04-12T02:18:31.723078Z","shell.execute_reply.started":"2024-04-12T02:18:31.711378Z","shell.execute_reply":"2024-04-12T02:18:31.722083Z"},"trusted":true},"execution_count":39,"outputs":[]},{"cell_type":"code","source":"class EarlyStopper:\n    def __init__(self, patience=1, min_delta=0):\n        self.patience = patience\n        self.min_delta = min_delta\n        self.counter = 0\n        self.min_validation_loss = float(\"inf\")\n\n    def early_stop(self, validation_loss):\n        if validation_loss < self.min_validation_loss:\n            self.min_validation_loss = validation_loss\n            self.counter = 0\n        elif validation_loss > (self.min_validation_loss + self.min_delta):\n            self.counter += 1\n            if self.counter >= self.patience:\n                return True\n        return False\n\n\ndef get_optimizers(model):\n    criterion = nn.CrossEntropyLoss()\n    optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9, weight_decay=5e-4)\n    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=200)\n    early_stopper = EarlyStopper(patience=10, min_delta=10)\n\n    return criterion, optimizer, scheduler, early_stopper","metadata":{"execution":{"iopub.status.busy":"2024-04-12T02:18:32.249618Z","iopub.execute_input":"2024-04-12T02:18:32.250646Z","iopub.status.idle":"2024-04-12T02:18:32.265343Z","shell.execute_reply.started":"2024-04-12T02:18:32.250601Z","shell.execute_reply":"2024-04-12T02:18:32.263147Z"},"trusted":true},"execution_count":40,"outputs":[]},{"cell_type":"code","source":"model = MiniResNet(num_blocks=[2,1,1,1] ).cuda()","metadata":{"execution":{"iopub.status.busy":"2024-04-12T02:18:33.382143Z","iopub.execute_input":"2024-04-12T02:18:33.382905Z","iopub.status.idle":"2024-04-12T02:18:33.452601Z","shell.execute_reply.started":"2024-04-12T02:18:33.382873Z","shell.execute_reply":"2024-04-12T02:18:33.451693Z"},"trusted":true},"execution_count":41,"outputs":[]},{"cell_type":"code","source":"def count_parameters(model):\n    return sum(p.numel() for p in model.parameters() if p.requires_grad)","metadata":{"execution":{"iopub.status.busy":"2024-04-12T02:18:34.457034Z","iopub.execute_input":"2024-04-12T02:18:34.458235Z","iopub.status.idle":"2024-04-12T02:18:34.463104Z","shell.execute_reply.started":"2024-04-12T02:18:34.458191Z","shell.execute_reply":"2024-04-12T02:18:34.462159Z"},"trusted":true},"execution_count":42,"outputs":[]},{"cell_type":"code","source":"count_parameters(model)","metadata":{"execution":{"iopub.status.busy":"2024-04-12T02:18:35.181353Z","iopub.execute_input":"2024-04-12T02:18:35.181729Z","iopub.status.idle":"2024-04-12T02:18:35.188034Z","shell.execute_reply.started":"2024-04-12T02:18:35.181700Z","shell.execute_reply":"2024-04-12T02:18:35.187143Z"},"trusted":true},"execution_count":43,"outputs":[{"execution_count":43,"output_type":"execute_result","data":{"text/plain":"4977226"},"metadata":{}}]},{"cell_type":"code","source":"torchsummary.summary(model, input_dim)","metadata":{"execution":{"iopub.status.busy":"2024-04-12T02:18:36.455923Z","iopub.execute_input":"2024-04-12T02:18:36.456912Z","iopub.status.idle":"2024-04-12T02:18:36.473155Z","shell.execute_reply.started":"2024-04-12T02:18:36.456879Z","shell.execute_reply":"2024-04-12T02:18:36.472145Z"},"trusted":true},"execution_count":44,"outputs":[{"name":"stdout","text":"----------------------------------------------------------------\n        Layer (type)               Output Shape         Param #\n================================================================\n            Conv2d-1           [-1, 64, 32, 32]           1,728\n       BatchNorm2d-2           [-1, 64, 32, 32]             128\n            Conv2d-3           [-1, 64, 32, 32]          36,864\n       BatchNorm2d-4           [-1, 64, 32, 32]             128\n            Conv2d-5           [-1, 64, 32, 32]          36,864\n       BatchNorm2d-6           [-1, 64, 32, 32]             128\n     ResidualBlock-7           [-1, 64, 32, 32]               0\n            Conv2d-8           [-1, 64, 32, 32]          36,864\n       BatchNorm2d-9           [-1, 64, 32, 32]             128\n           Conv2d-10           [-1, 64, 32, 32]          36,864\n      BatchNorm2d-11           [-1, 64, 32, 32]             128\n    ResidualBlock-12           [-1, 64, 32, 32]               0\n           Conv2d-13          [-1, 128, 16, 16]          73,728\n      BatchNorm2d-14          [-1, 128, 16, 16]             256\n           Conv2d-15          [-1, 128, 16, 16]         147,456\n      BatchNorm2d-16          [-1, 128, 16, 16]             256\n           Conv2d-17          [-1, 128, 16, 16]           8,192\n      BatchNorm2d-18          [-1, 128, 16, 16]             256\n    ResidualBlock-19          [-1, 128, 16, 16]               0\n           Conv2d-20            [-1, 256, 8, 8]         294,912\n      BatchNorm2d-21            [-1, 256, 8, 8]             512\n           Conv2d-22            [-1, 256, 8, 8]         589,824\n      BatchNorm2d-23            [-1, 256, 8, 8]             512\n           Conv2d-24            [-1, 256, 8, 8]          32,768\n      BatchNorm2d-25            [-1, 256, 8, 8]             512\n    ResidualBlock-26            [-1, 256, 8, 8]               0\n           Conv2d-27            [-1, 512, 4, 4]       1,179,648\n      BatchNorm2d-28            [-1, 512, 4, 4]           1,024\n           Conv2d-29            [-1, 512, 4, 4]       2,359,296\n      BatchNorm2d-30            [-1, 512, 4, 4]           1,024\n           Conv2d-31            [-1, 512, 4, 4]         131,072\n      BatchNorm2d-32            [-1, 512, 4, 4]           1,024\n    ResidualBlock-33            [-1, 512, 4, 4]               0\n           Linear-34                   [-1, 10]           5,130\n================================================================\nTotal params: 4,977,226\nTrainable params: 4,977,226\nNon-trainable params: 0\n----------------------------------------------------------------\nInput size (MB): 0.01\nForward/backward pass size (MB): 9.06\nParams size (MB): 18.99\nEstimated Total Size (MB): 28.06\n----------------------------------------------------------------\n","output_type":"stream"}]},{"cell_type":"code","source":"model","metadata":{"execution":{"iopub.status.busy":"2024-04-12T02:18:37.096030Z","iopub.execute_input":"2024-04-12T02:18:37.096724Z","iopub.status.idle":"2024-04-12T02:18:37.103860Z","shell.execute_reply.started":"2024-04-12T02:18:37.096694Z","shell.execute_reply":"2024-04-12T02:18:37.102841Z"},"trusted":true},"execution_count":45,"outputs":[{"execution_count":45,"output_type":"execute_result","data":{"text/plain":"MiniResNet(\n  (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (layer1): Sequential(\n    (0): ResidualBlock(\n      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (shortcut): Sequential()\n    )\n    (1): ResidualBlock(\n      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (shortcut): Sequential()\n    )\n  )\n  (layer2): Sequential(\n    (0): ResidualBlock(\n      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (shortcut): Sequential(\n        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n  )\n  (layer3): Sequential(\n    (0): ResidualBlock(\n      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (shortcut): Sequential(\n        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n  )\n  (layer4): Sequential(\n    (0): ResidualBlock(\n      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (shortcut): Sequential(\n        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n  )\n  (linear): Linear(in_features=512, out_features=10, bias=True)\n)"},"metadata":{}}]},{"cell_type":"markdown","source":"# Train the model","metadata":{}},{"cell_type":"code","source":"import torch.backends.cudnn as cudnn\n\ndevice = 'cuda' if torch.cuda.is_available() else 'cpu'","metadata":{"execution":{"iopub.status.busy":"2024-04-12T02:18:38.350903Z","iopub.execute_input":"2024-04-12T02:18:38.351533Z","iopub.status.idle":"2024-04-12T02:18:38.356154Z","shell.execute_reply.started":"2024-04-12T02:18:38.351500Z","shell.execute_reply":"2024-04-12T02:18:38.355165Z"},"trusted":true},"execution_count":46,"outputs":[]},{"cell_type":"code","source":"device","metadata":{"execution":{"iopub.status.busy":"2024-04-12T02:18:38.981879Z","iopub.execute_input":"2024-04-12T02:18:38.982283Z","iopub.status.idle":"2024-04-12T02:18:38.988491Z","shell.execute_reply.started":"2024-04-12T02:18:38.982255Z","shell.execute_reply":"2024-04-12T02:18:38.987489Z"},"trusted":true},"execution_count":47,"outputs":[{"execution_count":47,"output_type":"execute_result","data":{"text/plain":"'cuda'"},"metadata":{}}]},{"cell_type":"code","source":"criterion, optimizer, scheduler, early_stopper = get_optimizers(model)","metadata":{"execution":{"iopub.status.busy":"2024-04-12T02:18:39.555399Z","iopub.execute_input":"2024-04-12T02:18:39.556106Z","iopub.status.idle":"2024-04-12T02:18:39.561229Z","shell.execute_reply.started":"2024-04-12T02:18:39.556068Z","shell.execute_reply":"2024-04-12T02:18:39.560228Z"},"trusted":true},"execution_count":48,"outputs":[]},{"cell_type":"code","source":"epochs = 50","metadata":{"execution":{"iopub.status.busy":"2024-04-12T02:18:40.323080Z","iopub.execute_input":"2024-04-12T02:18:40.323877Z","iopub.status.idle":"2024-04-12T02:18:40.328172Z","shell.execute_reply.started":"2024-04-12T02:18:40.323844Z","shell.execute_reply":"2024-04-12T02:18:40.327142Z"},"trusted":true},"execution_count":49,"outputs":[]},{"cell_type":"code","source":"def train_epoch(model, train_loader, criterion, optimizer, device):\n    model.train()\n    train_loss = 0\n    correct = 0\n    total = 0\n\n    for _, (inputs, targets) in enumerate(train_loader):\n        inputs, targets = inputs.to(device), targets.to(device)\n        optimizer.zero_grad()\n        outputs = model(inputs)\n        loss = criterion(outputs, targets)\n        loss.backward()\n        optimizer.step()\n\n        train_loss += loss.item()\n        _, predicted = outputs.max(1)\n        total += targets.size(0)\n        correct += predicted.eq(targets).sum().item()\n\n    return train_loss, correct, total\n","metadata":{"execution":{"iopub.status.busy":"2024-04-12T02:18:40.811689Z","iopub.execute_input":"2024-04-12T02:18:40.812556Z","iopub.status.idle":"2024-04-12T02:18:40.819799Z","shell.execute_reply.started":"2024-04-12T02:18:40.812524Z","shell.execute_reply":"2024-04-12T02:18:40.818849Z"},"trusted":true},"execution_count":50,"outputs":[]},{"cell_type":"code","source":"def train(\n    model,\n    train_loader,\n    test_loader,\n    epochs,\n    criterion,\n    optimizer,\n    scheduler,\n    early_stopper,\n    device,\n):\n    train_loss_history = []\n    train_acc_history = []\n    test_loss_history = []\n    test_acc_history = []\n\n    for epoch in range(epochs):\n        train_loss, train_correct, train_total = train_epoch(\n            model, train_loader, criterion, optimizer, device\n        )\n        test_loss, test_correct, test_total = test(\n            model, test_loader, criterion, device\n        )\n\n        train_loss = train_loss / len(train_loader)\n        test_loss = test_loss / len(test_loader)\n\n        train_acc = train_correct / train_total\n        test_acc = test_correct / test_total\n\n        train_loss_history += [train_loss]\n        test_loss_history += [test_loss]\n\n        train_acc_history.append(train_acc)\n        test_acc_history.append(test_acc)\n\n        print(\n            f\"Epoch {epoch + 1}, Train loss {train_loss:.3f}, Test loss {test_loss:.3f}, Train Accuracy: {train_acc:.3f}, Test Accuracy: {test_acc:.3f}\"\n        )\n        scheduler.step()\n\n        if (epoch % 10 == 0) or early_stopper.early_stop(test_loss):\n            state = {\n                \"epoch\": epoch,\n                \"state_dict\": model.state_dict(),\n                \"optimizer_state_dict\": optimizer.state_dict(),\n                \"loss\": test_loss,\n            }\n            if not os.path.isdir(\"checkpoint\"):\n                os.mkdir(\"checkpoint\")\n                torch.save(state, \"./checkpoint/ckpt.pth\")","metadata":{"execution":{"iopub.status.busy":"2024-04-12T02:18:41.390422Z","iopub.execute_input":"2024-04-12T02:18:41.391309Z","iopub.status.idle":"2024-04-12T02:18:41.400830Z","shell.execute_reply.started":"2024-04-12T02:18:41.391275Z","shell.execute_reply":"2024-04-12T02:18:41.399966Z"},"trusted":true},"execution_count":51,"outputs":[]},{"cell_type":"code","source":"def test(model, test_loader, criterion, device):\n    model.eval()\n    test_loss = 0\n    correct = 0\n    total = 0\n\n    with torch.no_grad():\n        for _, (inputs, targets) in enumerate(test_loader):\n            inputs, targets = inputs.to(device), targets.to(device)\n            outputs = model(inputs)\n            loss = criterion(outputs, targets)\n\n            test_loss += loss.item()\n            _, predicted = outputs.max(1)\n            total += targets.size(0)\n            correct += predicted.eq(targets).sum().item()\n\n    return test_loss, correct, total","metadata":{"execution":{"iopub.status.busy":"2024-04-12T02:18:41.930012Z","iopub.execute_input":"2024-04-12T02:18:41.930735Z","iopub.status.idle":"2024-04-12T02:18:41.937649Z","shell.execute_reply.started":"2024-04-12T02:18:41.930702Z","shell.execute_reply":"2024-04-12T02:18:41.936555Z"},"trusted":true},"execution_count":52,"outputs":[]},{"cell_type":"code","source":" train(\n        model,\n        trainloader,\n        val_loader,\n        epochs,\n        criterion,\n        optimizer,\n        scheduler,\n        early_stopper,\n        device,\n    )","metadata":{"execution":{"iopub.status.busy":"2024-04-12T02:18:42.725669Z","iopub.execute_input":"2024-04-12T02:18:42.726614Z","iopub.status.idle":"2024-04-12T02:51:45.874099Z","shell.execute_reply.started":"2024-04-12T02:18:42.726573Z","shell.execute_reply":"2024-04-12T02:51:45.872907Z"},"trusted":true},"execution_count":53,"outputs":[{"name":"stdout","text":"Epoch 1, Train loss 2.194, Test loss 1.667, Train Accuracy: 0.251, Test Accuracy: 0.382\nEpoch 2, Train loss 1.628, Test loss 1.423, Train Accuracy: 0.401, Test Accuracy: 0.468\nEpoch 3, Train loss 1.405, Test loss 1.222, Train Accuracy: 0.486, Test Accuracy: 0.558\nEpoch 4, Train loss 1.232, Test loss 1.147, Train Accuracy: 0.559, Test Accuracy: 0.603\nEpoch 5, Train loss 1.111, Test loss 0.938, Train Accuracy: 0.604, Test Accuracy: 0.665\nEpoch 6, Train loss 1.011, Test loss 0.890, Train Accuracy: 0.641, Test Accuracy: 0.686\nEpoch 7, Train loss 0.940, Test loss 0.793, Train Accuracy: 0.669, Test Accuracy: 0.724\nEpoch 8, Train loss 0.860, Test loss 0.811, Train Accuracy: 0.699, Test Accuracy: 0.727\nEpoch 9, Train loss 0.806, Test loss 0.686, Train Accuracy: 0.715, Test Accuracy: 0.765\nEpoch 10, Train loss 0.746, Test loss 0.661, Train Accuracy: 0.739, Test Accuracy: 0.770\nEpoch 11, Train loss 0.693, Test loss 0.610, Train Accuracy: 0.758, Test Accuracy: 0.789\nEpoch 12, Train loss 0.663, Test loss 0.603, Train Accuracy: 0.769, Test Accuracy: 0.794\nEpoch 13, Train loss 0.631, Test loss 0.595, Train Accuracy: 0.780, Test Accuracy: 0.796\nEpoch 14, Train loss 0.607, Test loss 0.520, Train Accuracy: 0.790, Test Accuracy: 0.827\nEpoch 15, Train loss 0.571, Test loss 0.540, Train Accuracy: 0.800, Test Accuracy: 0.820\nEpoch 16, Train loss 0.553, Test loss 0.462, Train Accuracy: 0.807, Test Accuracy: 0.843\nEpoch 17, Train loss 0.537, Test loss 0.535, Train Accuracy: 0.813, Test Accuracy: 0.823\nEpoch 18, Train loss 0.514, Test loss 0.465, Train Accuracy: 0.821, Test Accuracy: 0.843\nEpoch 19, Train loss 0.498, Test loss 0.510, Train Accuracy: 0.826, Test Accuracy: 0.829\nEpoch 20, Train loss 0.486, Test loss 0.458, Train Accuracy: 0.830, Test Accuracy: 0.847\nEpoch 21, Train loss 0.465, Test loss 0.440, Train Accuracy: 0.838, Test Accuracy: 0.851\nEpoch 22, Train loss 0.452, Test loss 0.414, Train Accuracy: 0.843, Test Accuracy: 0.859\nEpoch 23, Train loss 0.437, Test loss 0.417, Train Accuracy: 0.849, Test Accuracy: 0.859\nEpoch 24, Train loss 0.421, Test loss 0.387, Train Accuracy: 0.854, Test Accuracy: 0.872\nEpoch 25, Train loss 0.416, Test loss 0.381, Train Accuracy: 0.854, Test Accuracy: 0.873\nEpoch 26, Train loss 0.397, Test loss 0.399, Train Accuracy: 0.862, Test Accuracy: 0.867\nEpoch 27, Train loss 0.391, Test loss 0.372, Train Accuracy: 0.863, Test Accuracy: 0.880\nEpoch 28, Train loss 0.382, Test loss 0.368, Train Accuracy: 0.868, Test Accuracy: 0.880\nEpoch 29, Train loss 0.369, Test loss 0.381, Train Accuracy: 0.871, Test Accuracy: 0.873\nEpoch 30, Train loss 0.356, Test loss 0.385, Train Accuracy: 0.875, Test Accuracy: 0.874\nEpoch 31, Train loss 0.359, Test loss 0.357, Train Accuracy: 0.876, Test Accuracy: 0.880\nEpoch 32, Train loss 0.337, Test loss 0.354, Train Accuracy: 0.882, Test Accuracy: 0.883\nEpoch 33, Train loss 0.334, Test loss 0.356, Train Accuracy: 0.884, Test Accuracy: 0.884\nEpoch 34, Train loss 0.328, Test loss 0.358, Train Accuracy: 0.886, Test Accuracy: 0.883\nEpoch 35, Train loss 0.318, Test loss 0.385, Train Accuracy: 0.888, Test Accuracy: 0.878\nEpoch 36, Train loss 0.311, Test loss 0.355, Train Accuracy: 0.892, Test Accuracy: 0.878\nEpoch 37, Train loss 0.305, Test loss 0.329, Train Accuracy: 0.894, Test Accuracy: 0.893\nEpoch 38, Train loss 0.303, Test loss 0.346, Train Accuracy: 0.893, Test Accuracy: 0.888\nEpoch 39, Train loss 0.291, Test loss 0.362, Train Accuracy: 0.896, Test Accuracy: 0.882\nEpoch 40, Train loss 0.287, Test loss 0.352, Train Accuracy: 0.899, Test Accuracy: 0.886\nEpoch 41, Train loss 0.274, Test loss 0.324, Train Accuracy: 0.904, Test Accuracy: 0.894\nEpoch 42, Train loss 0.272, Test loss 0.337, Train Accuracy: 0.905, Test Accuracy: 0.893\nEpoch 43, Train loss 0.268, Test loss 0.332, Train Accuracy: 0.905, Test Accuracy: 0.894\nEpoch 44, Train loss 0.259, Test loss 0.355, Train Accuracy: 0.908, Test Accuracy: 0.885\nEpoch 45, Train loss 0.256, Test loss 0.323, Train Accuracy: 0.909, Test Accuracy: 0.896\nEpoch 46, Train loss 0.248, Test loss 0.301, Train Accuracy: 0.913, Test Accuracy: 0.900\nEpoch 47, Train loss 0.248, Test loss 0.348, Train Accuracy: 0.913, Test Accuracy: 0.888\nEpoch 48, Train loss 0.244, Test loss 0.293, Train Accuracy: 0.913, Test Accuracy: 0.904\nEpoch 49, Train loss 0.233, Test loss 0.321, Train Accuracy: 0.918, Test Accuracy: 0.895\nEpoch 50, Train loss 0.232, Test loss 0.332, Train Accuracy: 0.917, Test Accuracy: 0.895\n","output_type":"stream"}]},{"cell_type":"code","source":" train(\n        model,\n        trainloader,\n        val_loader,\n        epochs,\n        criterion,\n        optimizer,\n        scheduler,\n        early_stopper,\n        device,\n    )","metadata":{"execution":{"iopub.status.busy":"2024-04-12T02:53:27.553144Z","iopub.execute_input":"2024-04-12T02:53:27.553990Z","iopub.status.idle":"2024-04-12T03:25:48.762277Z","shell.execute_reply.started":"2024-04-12T02:53:27.553956Z","shell.execute_reply":"2024-04-12T03:25:48.761039Z"},"trusted":true},"execution_count":54,"outputs":[{"name":"stdout","text":"Epoch 1, Train loss 0.229, Test loss 0.287, Train Accuracy: 0.920, Test Accuracy: 0.906\nEpoch 2, Train loss 0.222, Test loss 0.294, Train Accuracy: 0.923, Test Accuracy: 0.905\nEpoch 3, Train loss 0.218, Test loss 0.324, Train Accuracy: 0.924, Test Accuracy: 0.897\nEpoch 4, Train loss 0.216, Test loss 0.296, Train Accuracy: 0.925, Test Accuracy: 0.901\nEpoch 5, Train loss 0.206, Test loss 0.291, Train Accuracy: 0.927, Test Accuracy: 0.909\nEpoch 6, Train loss 0.208, Test loss 0.278, Train Accuracy: 0.926, Test Accuracy: 0.911\nEpoch 7, Train loss 0.205, Test loss 0.278, Train Accuracy: 0.927, Test Accuracy: 0.910\nEpoch 8, Train loss 0.198, Test loss 0.279, Train Accuracy: 0.931, Test Accuracy: 0.910\nEpoch 9, Train loss 0.195, Test loss 0.314, Train Accuracy: 0.932, Test Accuracy: 0.904\nEpoch 10, Train loss 0.190, Test loss 0.298, Train Accuracy: 0.932, Test Accuracy: 0.907\nEpoch 11, Train loss 0.190, Test loss 0.306, Train Accuracy: 0.932, Test Accuracy: 0.907\nEpoch 12, Train loss 0.183, Test loss 0.290, Train Accuracy: 0.936, Test Accuracy: 0.910\nEpoch 13, Train loss 0.178, Test loss 0.285, Train Accuracy: 0.938, Test Accuracy: 0.912\nEpoch 14, Train loss 0.177, Test loss 0.298, Train Accuracy: 0.938, Test Accuracy: 0.909\nEpoch 15, Train loss 0.178, Test loss 0.274, Train Accuracy: 0.938, Test Accuracy: 0.915\nEpoch 16, Train loss 0.171, Test loss 0.342, Train Accuracy: 0.939, Test Accuracy: 0.896\nEpoch 17, Train loss 0.171, Test loss 0.284, Train Accuracy: 0.940, Test Accuracy: 0.911\nEpoch 18, Train loss 0.165, Test loss 0.282, Train Accuracy: 0.943, Test Accuracy: 0.913\nEpoch 19, Train loss 0.167, Test loss 0.278, Train Accuracy: 0.942, Test Accuracy: 0.912\nEpoch 20, Train loss 0.156, Test loss 0.328, Train Accuracy: 0.945, Test Accuracy: 0.901\nEpoch 21, Train loss 0.155, Test loss 0.292, Train Accuracy: 0.945, Test Accuracy: 0.909\nEpoch 22, Train loss 0.158, Test loss 0.273, Train Accuracy: 0.945, Test Accuracy: 0.913\nEpoch 23, Train loss 0.152, Test loss 0.303, Train Accuracy: 0.947, Test Accuracy: 0.907\nEpoch 24, Train loss 0.147, Test loss 0.275, Train Accuracy: 0.949, Test Accuracy: 0.915\nEpoch 25, Train loss 0.148, Test loss 0.271, Train Accuracy: 0.949, Test Accuracy: 0.913\nEpoch 26, Train loss 0.145, Test loss 0.275, Train Accuracy: 0.949, Test Accuracy: 0.918\nEpoch 27, Train loss 0.146, Test loss 0.284, Train Accuracy: 0.949, Test Accuracy: 0.911\nEpoch 28, Train loss 0.137, Test loss 0.295, Train Accuracy: 0.952, Test Accuracy: 0.911\nEpoch 29, Train loss 0.141, Test loss 0.267, Train Accuracy: 0.950, Test Accuracy: 0.919\nEpoch 30, Train loss 0.136, Test loss 0.324, Train Accuracy: 0.952, Test Accuracy: 0.905\nEpoch 31, Train loss 0.130, Test loss 0.261, Train Accuracy: 0.955, Test Accuracy: 0.920\nEpoch 32, Train loss 0.125, Test loss 0.270, Train Accuracy: 0.957, Test Accuracy: 0.918\nEpoch 33, Train loss 0.126, Test loss 0.263, Train Accuracy: 0.956, Test Accuracy: 0.921\nEpoch 34, Train loss 0.126, Test loss 0.261, Train Accuracy: 0.956, Test Accuracy: 0.921\nEpoch 35, Train loss 0.125, Test loss 0.255, Train Accuracy: 0.956, Test Accuracy: 0.920\nEpoch 36, Train loss 0.120, Test loss 0.272, Train Accuracy: 0.959, Test Accuracy: 0.919\nEpoch 37, Train loss 0.117, Test loss 0.278, Train Accuracy: 0.960, Test Accuracy: 0.914\nEpoch 38, Train loss 0.114, Test loss 0.267, Train Accuracy: 0.960, Test Accuracy: 0.918\nEpoch 39, Train loss 0.116, Test loss 0.266, Train Accuracy: 0.960, Test Accuracy: 0.918\nEpoch 40, Train loss 0.112, Test loss 0.285, Train Accuracy: 0.961, Test Accuracy: 0.914\nEpoch 41, Train loss 0.111, Test loss 0.267, Train Accuracy: 0.962, Test Accuracy: 0.920\nEpoch 42, Train loss 0.110, Test loss 0.258, Train Accuracy: 0.962, Test Accuracy: 0.924\nEpoch 43, Train loss 0.107, Test loss 0.271, Train Accuracy: 0.962, Test Accuracy: 0.918\nEpoch 44, Train loss 0.108, Test loss 0.252, Train Accuracy: 0.963, Test Accuracy: 0.922\nEpoch 45, Train loss 0.103, Test loss 0.280, Train Accuracy: 0.964, Test Accuracy: 0.919\nEpoch 46, Train loss 0.100, Test loss 0.271, Train Accuracy: 0.965, Test Accuracy: 0.920\nEpoch 47, Train loss 0.100, Test loss 0.272, Train Accuracy: 0.966, Test Accuracy: 0.921\nEpoch 48, Train loss 0.092, Test loss 0.268, Train Accuracy: 0.968, Test Accuracy: 0.921\nEpoch 49, Train loss 0.091, Test loss 0.310, Train Accuracy: 0.970, Test Accuracy: 0.911\nEpoch 50, Train loss 0.094, Test loss 0.258, Train Accuracy: 0.968, Test Accuracy: 0.923\n","output_type":"stream"}]},{"cell_type":"code","source":"train(\n        model,\n        trainloader,\n        val_loader,\n        epochs,\n        criterion,\n        optimizer,\n        scheduler,\n        early_stopper,\n        device,\n    )","metadata":{"execution":{"iopub.status.busy":"2024-04-12T03:30:03.829563Z","iopub.execute_input":"2024-04-12T03:30:03.830393Z","iopub.status.idle":"2024-04-12T04:02:12.123733Z","shell.execute_reply.started":"2024-04-12T03:30:03.830356Z","shell.execute_reply":"2024-04-12T04:02:12.122381Z"},"trusted":true},"execution_count":55,"outputs":[{"name":"stdout","text":"Epoch 1, Train loss 0.093, Test loss 0.274, Train Accuracy: 0.969, Test Accuracy: 0.919\nEpoch 2, Train loss 0.088, Test loss 0.253, Train Accuracy: 0.970, Test Accuracy: 0.923\nEpoch 3, Train loss 0.088, Test loss 0.248, Train Accuracy: 0.970, Test Accuracy: 0.925\nEpoch 4, Train loss 0.083, Test loss 0.262, Train Accuracy: 0.972, Test Accuracy: 0.922\nEpoch 5, Train loss 0.084, Test loss 0.264, Train Accuracy: 0.972, Test Accuracy: 0.924\nEpoch 6, Train loss 0.084, Test loss 0.250, Train Accuracy: 0.972, Test Accuracy: 0.925\nEpoch 7, Train loss 0.076, Test loss 0.262, Train Accuracy: 0.974, Test Accuracy: 0.922\nEpoch 8, Train loss 0.077, Test loss 0.254, Train Accuracy: 0.974, Test Accuracy: 0.927\nEpoch 9, Train loss 0.074, Test loss 0.256, Train Accuracy: 0.976, Test Accuracy: 0.925\nEpoch 10, Train loss 0.075, Test loss 0.257, Train Accuracy: 0.975, Test Accuracy: 0.926\nEpoch 11, Train loss 0.069, Test loss 0.253, Train Accuracy: 0.977, Test Accuracy: 0.926\nEpoch 12, Train loss 0.071, Test loss 0.261, Train Accuracy: 0.976, Test Accuracy: 0.927\nEpoch 13, Train loss 0.069, Test loss 0.256, Train Accuracy: 0.977, Test Accuracy: 0.927\nEpoch 14, Train loss 0.067, Test loss 0.245, Train Accuracy: 0.978, Test Accuracy: 0.926\nEpoch 15, Train loss 0.066, Test loss 0.253, Train Accuracy: 0.978, Test Accuracy: 0.927\nEpoch 16, Train loss 0.064, Test loss 0.253, Train Accuracy: 0.978, Test Accuracy: 0.926\nEpoch 17, Train loss 0.062, Test loss 0.249, Train Accuracy: 0.979, Test Accuracy: 0.926\nEpoch 18, Train loss 0.061, Test loss 0.248, Train Accuracy: 0.980, Test Accuracy: 0.929\nEpoch 19, Train loss 0.062, Test loss 0.253, Train Accuracy: 0.979, Test Accuracy: 0.925\nEpoch 20, Train loss 0.058, Test loss 0.245, Train Accuracy: 0.981, Test Accuracy: 0.928\nEpoch 21, Train loss 0.059, Test loss 0.253, Train Accuracy: 0.981, Test Accuracy: 0.924\nEpoch 22, Train loss 0.057, Test loss 0.257, Train Accuracy: 0.982, Test Accuracy: 0.924\nEpoch 23, Train loss 0.055, Test loss 0.253, Train Accuracy: 0.982, Test Accuracy: 0.927\nEpoch 24, Train loss 0.052, Test loss 0.247, Train Accuracy: 0.983, Test Accuracy: 0.929\nEpoch 25, Train loss 0.049, Test loss 0.242, Train Accuracy: 0.984, Test Accuracy: 0.928\nEpoch 26, Train loss 0.048, Test loss 0.250, Train Accuracy: 0.985, Test Accuracy: 0.931\nEpoch 27, Train loss 0.049, Test loss 0.241, Train Accuracy: 0.984, Test Accuracy: 0.931\nEpoch 28, Train loss 0.048, Test loss 0.233, Train Accuracy: 0.985, Test Accuracy: 0.931\nEpoch 29, Train loss 0.046, Test loss 0.240, Train Accuracy: 0.985, Test Accuracy: 0.933\nEpoch 30, Train loss 0.046, Test loss 0.243, Train Accuracy: 0.986, Test Accuracy: 0.931\nEpoch 31, Train loss 0.041, Test loss 0.254, Train Accuracy: 0.988, Test Accuracy: 0.930\nEpoch 32, Train loss 0.042, Test loss 0.243, Train Accuracy: 0.987, Test Accuracy: 0.931\nEpoch 33, Train loss 0.039, Test loss 0.239, Train Accuracy: 0.988, Test Accuracy: 0.932\nEpoch 34, Train loss 0.042, Test loss 0.239, Train Accuracy: 0.987, Test Accuracy: 0.932\nEpoch 35, Train loss 0.038, Test loss 0.233, Train Accuracy: 0.988, Test Accuracy: 0.934\nEpoch 36, Train loss 0.036, Test loss 0.232, Train Accuracy: 0.989, Test Accuracy: 0.935\nEpoch 37, Train loss 0.036, Test loss 0.232, Train Accuracy: 0.989, Test Accuracy: 0.936\nEpoch 38, Train loss 0.035, Test loss 0.239, Train Accuracy: 0.989, Test Accuracy: 0.933\nEpoch 39, Train loss 0.036, Test loss 0.241, Train Accuracy: 0.989, Test Accuracy: 0.933\nEpoch 40, Train loss 0.033, Test loss 0.239, Train Accuracy: 0.990, Test Accuracy: 0.934\nEpoch 41, Train loss 0.033, Test loss 0.257, Train Accuracy: 0.990, Test Accuracy: 0.927\nEpoch 42, Train loss 0.032, Test loss 0.234, Train Accuracy: 0.991, Test Accuracy: 0.936\nEpoch 43, Train loss 0.031, Test loss 0.239, Train Accuracy: 0.991, Test Accuracy: 0.934\nEpoch 44, Train loss 0.028, Test loss 0.240, Train Accuracy: 0.992, Test Accuracy: 0.933\nEpoch 45, Train loss 0.029, Test loss 0.243, Train Accuracy: 0.992, Test Accuracy: 0.932\nEpoch 46, Train loss 0.028, Test loss 0.246, Train Accuracy: 0.992, Test Accuracy: 0.934\nEpoch 47, Train loss 0.027, Test loss 0.249, Train Accuracy: 0.993, Test Accuracy: 0.933\nEpoch 48, Train loss 0.026, Test loss 0.234, Train Accuracy: 0.993, Test Accuracy: 0.935\nEpoch 49, Train loss 0.025, Test loss 0.239, Train Accuracy: 0.993, Test Accuracy: 0.934\nEpoch 50, Train loss 0.026, Test loss 0.236, Train Accuracy: 0.993, Test Accuracy: 0.934\n","output_type":"stream"}]},{"cell_type":"code","source":"    valid_loss, valid_correct, valid_total = test(model, val_loader, criterion, device)\n    valid_acc = valid_correct / valid_total\n    print(f\"Valid Accuracy: {valid_acc}\")","metadata":{"execution":{"iopub.status.busy":"2024-04-12T04:08:38.173022Z","iopub.execute_input":"2024-04-12T04:08:38.173460Z","iopub.status.idle":"2024-04-12T04:08:40.386177Z","shell.execute_reply.started":"2024-04-12T04:08:38.173424Z","shell.execute_reply":"2024-04-12T04:08:40.385030Z"},"trusted":true},"execution_count":56,"outputs":[{"name":"stdout","text":"Valid Accuracy: 0.9335\n","output_type":"stream"}]},{"cell_type":"code","source":"def infer(model, test_loader, criterion, device):\n    print(len(test_loader))\n    model.eval()\n\n    results = []\n\n    for _, (id_, image) in enumerate(test_loader):\n        image = image.to(device)\n        output = model(image)\n        _, predicted = output.max(1)\n        results.append({\"ID\": id_.item(), \"Labels\": predicted.item()})\n\n    return pd.DataFrame(results)","metadata":{"execution":{"iopub.status.busy":"2024-04-12T04:08:40.388146Z","iopub.execute_input":"2024-04-12T04:08:40.388464Z","iopub.status.idle":"2024-04-12T04:08:40.394947Z","shell.execute_reply.started":"2024-04-12T04:08:40.388435Z","shell.execute_reply":"2024-04-12T04:08:40.393956Z"},"trusted":true},"execution_count":57,"outputs":[]},{"cell_type":"code","source":"results = infer(model, testloader, criterion, device)\n","metadata":{"execution":{"iopub.status.busy":"2024-04-12T04:08:40.396030Z","iopub.execute_input":"2024-04-12T04:08:40.396335Z","iopub.status.idle":"2024-04-12T04:09:19.026678Z","shell.execute_reply.started":"2024-04-12T04:08:40.396312Z","shell.execute_reply":"2024-04-12T04:09:19.025649Z"},"trusted":true},"execution_count":58,"outputs":[{"name":"stdout","text":"10000\n","output_type":"stream"}]},{"cell_type":"code","source":"results.head(80)","metadata":{"execution":{"iopub.status.busy":"2024-04-12T04:09:19.028703Z","iopub.execute_input":"2024-04-12T04:09:19.029060Z","iopub.status.idle":"2024-04-12T04:09:19.041143Z","shell.execute_reply.started":"2024-04-12T04:09:19.029000Z","shell.execute_reply":"2024-04-12T04:09:19.040299Z"},"trusted":true},"execution_count":59,"outputs":[{"execution_count":59,"output_type":"execute_result","data":{"text/plain":"    ID  Labels\n0    0       8\n1    1       8\n2    2       8\n3    3       0\n4    4       8\n..  ..     ...\n75  75       8\n76  76       8\n77  77       8\n78  78       8\n79  79       8\n\n[80 rows x 2 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ID</th>\n      <th>Labels</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>8</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>8</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>8</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>8</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>75</th>\n      <td>75</td>\n      <td>8</td>\n    </tr>\n    <tr>\n      <th>76</th>\n      <td>76</td>\n      <td>8</td>\n    </tr>\n    <tr>\n      <th>77</th>\n      <td>77</td>\n      <td>8</td>\n    </tr>\n    <tr>\n      <th>78</th>\n      <td>78</td>\n      <td>8</td>\n    </tr>\n    <tr>\n      <th>79</th>\n      <td>79</td>\n      <td>8</td>\n    </tr>\n  </tbody>\n</table>\n<p>80 rows × 2 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"import numpy as np\nnp.unique(results['Labels'],return_counts=True)","metadata":{"execution":{"iopub.status.busy":"2024-04-12T02:07:45.092191Z","iopub.execute_input":"2024-04-12T02:07:45.092569Z","iopub.status.idle":"2024-04-12T02:07:45.105916Z","shell.execute_reply.started":"2024-04-12T02:07:45.092540Z","shell.execute_reply":"2024-04-12T02:07:45.104914Z"},"trusted":true},"execution_count":31,"outputs":[{"execution_count":31,"output_type":"execute_result","data":{"text/plain":"(array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]),\n array([ 856, 1004,  913, 1162,  964, 1039,  913, 1013, 1098, 1038]))"},"metadata":{}}]},{"cell_type":"code","source":"results.to_csv('/kaggle/working/results.csv', index =False)","metadata":{"execution":{"iopub.status.busy":"2024-04-12T02:07:45.854133Z","iopub.execute_input":"2024-04-12T02:07:45.854495Z","iopub.status.idle":"2024-04-12T02:07:45.876651Z","shell.execute_reply.started":"2024-04-12T02:07:45.854468Z","shell.execute_reply":"2024-04-12T02:07:45.875845Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}
