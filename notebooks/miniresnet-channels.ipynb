{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":8095629,"sourceType":"datasetVersion","datasetId":4779931}],"dockerImageVersionId":30683,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"Previous iterations of our experiments have centered around training models that use the same residual block architecture as ResNet18 (in terms of the convolutional layers per residual block), but changing the number of blocks per layer. In this notebook,we keep the number of residual blocks per layer the same, but instead change the number of channels in the convolutional layers in each residual block. ","metadata":{}},{"cell_type":"code","source":"!pip install torchsummary","metadata":{"execution":{"iopub.status.busy":"2024-04-12T03:01:54.541610Z","iopub.execute_input":"2024-04-12T03:01:54.542278Z","iopub.status.idle":"2024-04-12T03:02:06.621973Z","shell.execute_reply.started":"2024-04-12T03:01:54.542239Z","shell.execute_reply":"2024-04-12T03:02:06.620919Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Requirement already satisfied: torchsummary in /opt/conda/lib/python3.10/site-packages (1.5.1)\n","output_type":"stream"}]},{"cell_type":"code","source":"import torch\nimport torchvision.transforms as transforms\nfrom torchvision import datasets\nimport pickle\nfrom PIL import Image\nimport torchsummary\nimport warnings\nimport os\nimport pandas as pd\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim","metadata":{"execution":{"iopub.status.busy":"2024-04-12T03:02:06.624413Z","iopub.execute_input":"2024-04-12T03:02:06.624831Z","iopub.status.idle":"2024-04-12T03:02:10.162586Z","shell.execute_reply.started":"2024-04-12T03:02:06.624792Z","shell.execute_reply":"2024-04-12T03:02:10.161733Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"# Load the Data","metadata":{}},{"cell_type":"code","source":"class TestData(torch.utils.data.Dataset):\n    def __init__(self, file_path, transform=None):\n        self.data = None\n        with open(file_path, \"rb\") as f:\n            self.data = pickle.load(f)\n            self.images = self.data[b\"data\"]\n            self.ids = self.data[b\"ids\"]\n        self.transform = transform\n\n    def __len__(self):\n        return len(self.ids)\n\n    def __getitem__(self, index):\n        img = self.images[index]\n        id_ = self.ids[index]\n\n        # Convert image to PIL Image\n        img = img.reshape(3, 32, 32).transpose(1, 2, 0)\n        img = Image.fromarray(img)\n\n        if self.transform is not None:\n            img = self.transform(img)\n\n        return id_, img","metadata":{"execution":{"iopub.status.busy":"2024-04-12T03:02:15.481288Z","iopub.execute_input":"2024-04-12T03:02:15.481712Z","iopub.status.idle":"2024-04-12T03:02:15.493636Z","shell.execute_reply.started":"2024-04-12T03:02:15.481682Z","shell.execute_reply":"2024-04-12T03:02:15.492452Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"def augment_data(input_dim=(3, 32, 32)):\n    transform_train = transforms.Compose(\n        [\n            transforms.RandomHorizontalFlip(),\n            transforms.ColorJitter(\n                brightness=0.1, contrast=0.1, saturation=0.1, hue=0.1\n            ),\n            transforms.RandomCrop(input_dim[1], padding=4),\n            transforms.RandomAffine(degrees=10, translate=(0.1, 0.1), shear=15),\n            transforms.RandomAdjustSharpness(4.5, p=0.5),\n            transforms.ToTensor(),\n            transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n        ]\n    )\n\n    transform_val = transforms.Compose(\n        [\n            transforms.RandomAdjustSharpness(4.5, p=0.5),\n            transforms.ToTensor(),\n            transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n        ]\n    )\n    \n    transform_test = transforms.Compose(\n        [\n            transforms.RandomAdjustSharpness(4.5, p=0.5),\n            transforms.ToTensor(),\n            transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n        ]\n    )\n    return transform_train, transform_val, transform_test","metadata":{"execution":{"iopub.status.busy":"2024-04-12T03:02:22.202053Z","iopub.execute_input":"2024-04-12T03:02:22.202466Z","iopub.status.idle":"2024-04-12T03:02:22.212244Z","shell.execute_reply.started":"2024-04-12T03:02:22.202432Z","shell.execute_reply":"2024-04-12T03:02:22.211133Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"data_directory = \"./data\"\ninput_dim = (3,32,32)\n#test_path = \"/kaggle/input/test-set/cifar_test_nolabels.pkl\"\ntest_path = \"/kaggle/input/test-data/cifar_test_nolabels.pkl\"\n\ntransform_train, transform_val, transform_test = augment_data(input_dim)\n\ntrainset = datasets.CIFAR10(\n    root=data_directory, train=True, download=True, transform=transform_train\n)\ntrainloader = torch.utils.data.DataLoader(\n    trainset, batch_size=128, shuffle=True, num_workers=2\n)\n\nval_set = datasets.CIFAR10(\n    root=data_directory, train=False, download=True, transform=transform_val\n)\nval_loader = torch.utils.data.DataLoader(\n    val_set, batch_size=100, shuffle=False, num_workers=2\n)\n\ntest_set = TestData(file_path=test_path, transform=transform_test)\ntestloader = torch.utils.data.DataLoader(\n    test_set, batch_size=1, shuffle=False, num_workers=2\n)\n\nclasses = (\n    \"plane\",\n    \"car\",\n    \"bird\",\n    \"cat\",\n    \"deer\",\n    \"dog\",\n    \"frog\",\n    \"horse\",\n    \"ship\",\n    \"truck\",\n)\n","metadata":{"execution":{"iopub.status.busy":"2024-04-12T03:02:23.726593Z","iopub.execute_input":"2024-04-12T03:02:23.727274Z","iopub.status.idle":"2024-04-12T03:02:25.389620Z","shell.execute_reply.started":"2024-04-12T03:02:23.727239Z","shell.execute_reply":"2024-04-12T03:02:25.388788Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"Files already downloaded and verified\nFiles already downloaded and verified\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Define the model","metadata":{}},{"cell_type":"code","source":"class ResidualBlock(nn.Module):\n    expansion = 1\n\n    def __init__(self, in_planes, planes, stride=1):\n        super(ResidualBlock, self).__init__()\n        self.conv1 = nn.Conv2d(\n            in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False\n        )\n        self.bn1 = nn.BatchNorm2d(planes)\n        self.conv2 = nn.Conv2d(\n            planes, planes, kernel_size=3, stride=1, padding=1, bias=False\n        )\n        self.bn2 = nn.BatchNorm2d(planes)\n\n        self.shortcut = nn.Sequential()\n        if stride != 1 or in_planes != self.expansion * planes:\n            self.shortcut = nn.Sequential(\n                nn.Conv2d(\n                    in_planes,\n                    self.expansion * planes,\n                    kernel_size=1,\n                    stride=stride,\n                    bias=False,\n                ),\n                nn.BatchNorm2d(self.expansion * planes),\n            )\n\n    def forward(self, x):\n        out = F.relu(self.bn1(self.conv1(x)))\n        out = self.bn2(self.conv2(out))\n        out += self.shortcut(x)\n        out = F.relu(out)\n        return out","metadata":{"execution":{"iopub.status.busy":"2024-04-12T03:02:28.361248Z","iopub.execute_input":"2024-04-12T03:02:28.361890Z","iopub.status.idle":"2024-04-12T03:02:28.371407Z","shell.execute_reply.started":"2024-04-12T03:02:28.361857Z","shell.execute_reply":"2024-04-12T03:02:28.370364Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"class MiniResNet(nn.Module):\n    def __init__(self, num_blocks=(2, 2, 2, 2)):\n        super(MiniResNet, self).__init__()\n        self.in_planes = 64\n\n        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\n        self.bn1 = nn.BatchNorm2d(64)\n        self.layer1 = self._make_layer(64, num_blocks[0], stride=1)\n        self.layer2 = self._make_layer(128, num_blocks[1], stride=2)\n        self.layer3 = self._make_layer(128, num_blocks[2], stride=2)\n        self.layer4 = self._make_layer(256, num_blocks[3], stride=2)\n        self.linear = nn.Linear(256, 10)\n#         self.linear = nn.Linear(256, 10)\n\n    def _make_layer(self, planes, num_blocks, stride):\n        strides = [stride] + [1] * (num_blocks - 1)\n        layers = []\n        for stride in strides:\n            layers.append(ResidualBlock(self.in_planes, planes, stride))\n            self.in_planes = planes\n        return nn.Sequential(*layers)\n\n    def forward(self, x):\n        out = F.relu(self.bn1(self.conv1(x)))\n        out = self.layer1(out)\n        out = self.layer2(out)\n        out = self.layer3(out)\n        out = self.layer4(out)\n        out = F.avg_pool2d(out, 4)\n        out = out.view(out.size(0), -1)\n        out = self.linear(out)\n        return out","metadata":{"execution":{"iopub.status.busy":"2024-04-12T03:02:36.541645Z","iopub.execute_input":"2024-04-12T03:02:36.542394Z","iopub.status.idle":"2024-04-12T03:02:36.553694Z","shell.execute_reply.started":"2024-04-12T03:02:36.542359Z","shell.execute_reply":"2024-04-12T03:02:36.552642Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"class EarlyStopper:\n    def __init__(self, patience=1, min_delta=0):\n        self.patience = patience\n        self.min_delta = min_delta\n        self.counter = 0\n        self.min_validation_loss = float(\"inf\")\n\n    def early_stop(self, validation_loss):\n        if validation_loss < self.min_validation_loss:\n            self.min_validation_loss = validation_loss\n            self.counter = 0\n        elif validation_loss > (self.min_validation_loss + self.min_delta):\n            self.counter += 1\n            if self.counter >= self.patience:\n                return True\n        return False\n\n\ndef get_optimizers(model):\n    criterion = nn.CrossEntropyLoss()\n    optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9, weight_decay=5e-4)\n    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=200)\n    early_stopper = EarlyStopper(patience=10, min_delta=10)\n\n    return criterion, optimizer, scheduler, early_stopper","metadata":{"execution":{"iopub.status.busy":"2024-04-12T03:02:41.641749Z","iopub.execute_input":"2024-04-12T03:02:41.642379Z","iopub.status.idle":"2024-04-12T03:02:41.650245Z","shell.execute_reply.started":"2024-04-12T03:02:41.642344Z","shell.execute_reply":"2024-04-12T03:02:41.649276Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"model = MiniResNet(num_blocks=[2,2,2,2] ).cuda()","metadata":{"execution":{"iopub.status.busy":"2024-04-12T03:02:44.281492Z","iopub.execute_input":"2024-04-12T03:02:44.281877Z","iopub.status.idle":"2024-04-12T03:02:44.497551Z","shell.execute_reply.started":"2024-04-12T03:02:44.281845Z","shell.execute_reply":"2024-04-12T03:02:44.496677Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"torchsummary.summary(model, input_dim)","metadata":{"execution":{"iopub.status.busy":"2024-04-12T03:02:46.507483Z","iopub.execute_input":"2024-04-12T03:02:46.508458Z","iopub.status.idle":"2024-04-12T03:02:46.803850Z","shell.execute_reply.started":"2024-04-12T03:02:46.508404Z","shell.execute_reply":"2024-04-12T03:02:46.802638Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stdout","text":"----------------------------------------------------------------\n        Layer (type)               Output Shape         Param #\n================================================================\n            Conv2d-1           [-1, 64, 32, 32]           1,728\n       BatchNorm2d-2           [-1, 64, 32, 32]             128\n            Conv2d-3           [-1, 64, 32, 32]          36,864\n       BatchNorm2d-4           [-1, 64, 32, 32]             128\n            Conv2d-5           [-1, 64, 32, 32]          36,864\n       BatchNorm2d-6           [-1, 64, 32, 32]             128\n     ResidualBlock-7           [-1, 64, 32, 32]               0\n            Conv2d-8           [-1, 64, 32, 32]          36,864\n       BatchNorm2d-9           [-1, 64, 32, 32]             128\n           Conv2d-10           [-1, 64, 32, 32]          36,864\n      BatchNorm2d-11           [-1, 64, 32, 32]             128\n    ResidualBlock-12           [-1, 64, 32, 32]               0\n           Conv2d-13          [-1, 128, 16, 16]          73,728\n      BatchNorm2d-14          [-1, 128, 16, 16]             256\n           Conv2d-15          [-1, 128, 16, 16]         147,456\n      BatchNorm2d-16          [-1, 128, 16, 16]             256\n           Conv2d-17          [-1, 128, 16, 16]           8,192\n      BatchNorm2d-18          [-1, 128, 16, 16]             256\n    ResidualBlock-19          [-1, 128, 16, 16]               0\n           Conv2d-20          [-1, 128, 16, 16]         147,456\n      BatchNorm2d-21          [-1, 128, 16, 16]             256\n           Conv2d-22          [-1, 128, 16, 16]         147,456\n      BatchNorm2d-23          [-1, 128, 16, 16]             256\n    ResidualBlock-24          [-1, 128, 16, 16]               0\n           Conv2d-25            [-1, 128, 8, 8]         147,456\n      BatchNorm2d-26            [-1, 128, 8, 8]             256\n           Conv2d-27            [-1, 128, 8, 8]         147,456\n      BatchNorm2d-28            [-1, 128, 8, 8]             256\n           Conv2d-29            [-1, 128, 8, 8]          16,384\n      BatchNorm2d-30            [-1, 128, 8, 8]             256\n    ResidualBlock-31            [-1, 128, 8, 8]               0\n           Conv2d-32            [-1, 128, 8, 8]         147,456\n      BatchNorm2d-33            [-1, 128, 8, 8]             256\n           Conv2d-34            [-1, 128, 8, 8]         147,456\n      BatchNorm2d-35            [-1, 128, 8, 8]             256\n    ResidualBlock-36            [-1, 128, 8, 8]               0\n           Conv2d-37            [-1, 256, 4, 4]         294,912\n      BatchNorm2d-38            [-1, 256, 4, 4]             512\n           Conv2d-39            [-1, 256, 4, 4]         589,824\n      BatchNorm2d-40            [-1, 256, 4, 4]             512\n           Conv2d-41            [-1, 256, 4, 4]          32,768\n      BatchNorm2d-42            [-1, 256, 4, 4]             512\n    ResidualBlock-43            [-1, 256, 4, 4]               0\n           Conv2d-44            [-1, 256, 4, 4]         589,824\n      BatchNorm2d-45            [-1, 256, 4, 4]             512\n           Conv2d-46            [-1, 256, 4, 4]         589,824\n      BatchNorm2d-47            [-1, 256, 4, 4]             512\n    ResidualBlock-48            [-1, 256, 4, 4]               0\n           Linear-49                   [-1, 10]           2,570\n================================================================\nTotal params: 3,385,162\nTrainable params: 3,385,162\nNon-trainable params: 0\n----------------------------------------------------------------\nInput size (MB): 0.01\nForward/backward pass size (MB): 10.13\nParams size (MB): 12.91\nEstimated Total Size (MB): 23.05\n----------------------------------------------------------------\n","output_type":"stream"}]},{"cell_type":"code","source":"model","metadata":{"execution":{"iopub.status.busy":"2024-04-12T03:02:51.221341Z","iopub.execute_input":"2024-04-12T03:02:51.222298Z","iopub.status.idle":"2024-04-12T03:02:51.230531Z","shell.execute_reply.started":"2024-04-12T03:02:51.222259Z","shell.execute_reply":"2024-04-12T03:02:51.229502Z"},"trusted":true},"execution_count":12,"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"MiniResNet(\n  (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (layer1): Sequential(\n    (0): ResidualBlock(\n      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (shortcut): Sequential()\n    )\n    (1): ResidualBlock(\n      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (shortcut): Sequential()\n    )\n  )\n  (layer2): Sequential(\n    (0): ResidualBlock(\n      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (shortcut): Sequential(\n        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): ResidualBlock(\n      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (shortcut): Sequential()\n    )\n  )\n  (layer3): Sequential(\n    (0): ResidualBlock(\n      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (shortcut): Sequential(\n        (0): Conv2d(128, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): ResidualBlock(\n      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (shortcut): Sequential()\n    )\n  )\n  (layer4): Sequential(\n    (0): ResidualBlock(\n      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (shortcut): Sequential(\n        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): ResidualBlock(\n      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (shortcut): Sequential()\n    )\n  )\n  (linear): Linear(in_features=256, out_features=10, bias=True)\n)"},"metadata":{}}]},{"cell_type":"markdown","source":"# Train the model","metadata":{}},{"cell_type":"code","source":"import torch.backends.cudnn as cudnn\n\ndevice = 'cuda' if torch.cuda.is_available() else 'cpu'","metadata":{"execution":{"iopub.status.busy":"2024-04-12T03:02:54.485843Z","iopub.execute_input":"2024-04-12T03:02:54.486546Z","iopub.status.idle":"2024-04-12T03:02:54.491597Z","shell.execute_reply.started":"2024-04-12T03:02:54.486500Z","shell.execute_reply":"2024-04-12T03:02:54.490578Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"criterion, optimizer, scheduler, early_stopper = get_optimizers(model)","metadata":{"execution":{"iopub.status.busy":"2024-04-12T03:02:55.501233Z","iopub.execute_input":"2024-04-12T03:02:55.501613Z","iopub.status.idle":"2024-04-12T03:02:55.507521Z","shell.execute_reply.started":"2024-04-12T03:02:55.501585Z","shell.execute_reply":"2024-04-12T03:02:55.506304Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"epochs = 200","metadata":{"execution":{"iopub.status.busy":"2024-04-12T03:02:56.401556Z","iopub.execute_input":"2024-04-12T03:02:56.401918Z","iopub.status.idle":"2024-04-12T03:02:56.406454Z","shell.execute_reply.started":"2024-04-12T03:02:56.401889Z","shell.execute_reply":"2024-04-12T03:02:56.405387Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"def test(model, test_loader, criterion, device):\n    model.eval()\n    test_loss = 0\n    correct = 0\n    total = 0\n\n    with torch.no_grad():\n        for _, (inputs, targets) in enumerate(test_loader):\n            inputs, targets = inputs.to(device), targets.to(device)\n            outputs = model(inputs)\n            loss = criterion(outputs, targets)\n\n            test_loss += loss.item()\n            _, predicted = outputs.max(1)\n            total += targets.size(0)\n            correct += predicted.eq(targets).sum().item()\n\n    return test_loss, correct, total","metadata":{"execution":{"iopub.status.busy":"2024-04-12T03:02:57.866900Z","iopub.execute_input":"2024-04-12T03:02:57.867291Z","iopub.status.idle":"2024-04-12T03:02:57.874659Z","shell.execute_reply.started":"2024-04-12T03:02:57.867258Z","shell.execute_reply":"2024-04-12T03:02:57.873481Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"def train_epoch(model, train_loader, criterion, optimizer, device):\n    model.train()\n    train_loss = 0\n    correct = 0\n    total = 0\n\n    for _, (inputs, targets) in enumerate(train_loader):\n        inputs, targets = inputs.to(device), targets.to(device)\n        optimizer.zero_grad()\n        outputs = model(inputs)\n        loss = criterion(outputs, targets)\n        loss.backward()\n        optimizer.step()\n\n        train_loss += loss.item()\n        _, predicted = outputs.max(1)\n        total += targets.size(0)\n        correct += predicted.eq(targets).sum().item()\n\n    return train_loss, correct, total","metadata":{"execution":{"iopub.status.busy":"2024-04-12T03:02:59.481217Z","iopub.execute_input":"2024-04-12T03:02:59.481857Z","iopub.status.idle":"2024-04-12T03:02:59.488969Z","shell.execute_reply.started":"2024-04-12T03:02:59.481819Z","shell.execute_reply":"2024-04-12T03:02:59.487857Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def train(\n    model,\n    train_loader,\n    test_loader,\n    epochs,\n    criterion,\n    optimizer,\n    scheduler,\n    early_stopper,\n    device,\n):\n    train_loss_history = []\n    train_acc_history = []\n    test_loss_history = []\n    test_acc_history = []\n\n    for epoch in range(epochs):\n        train_loss, train_correct, train_total = train_epoch(\n            model, train_loader, criterion, optimizer, device\n        )\n        test_loss, test_correct, test_total = test(\n            model, test_loader, criterion, device\n        )\n\n        train_loss = train_loss / len(train_loader)\n        test_loss = test_loss / len(test_loader)\n\n        train_acc = train_correct / train_total\n        test_acc = test_correct / test_total\n\n        train_loss_history += [train_loss]\n        test_loss_history += [test_loss]\n\n        train_acc_history.append(train_acc)\n        test_acc_history.append(test_acc)\n\n        print(\n            f\"Epoch {epoch + 1}, Train loss {train_loss:.3f}, Test loss {test_loss:.3f}, Train Accuracy: {train_acc:.3f}, Test Accuracy: {test_acc:.3f}\"\n        )\n        scheduler.step()\n\n        if (epoch % 10 == 0) or early_stopper.early_stop(test_loss):\n            state = {\n                \"epoch\": epoch,\n                \"state_dict\": model.state_dict(),\n                \"optimizer_state_dict\": optimizer.state_dict(),\n                \"loss\": test_loss,\n            }\n            if not os.path.isdir(\"checkpoint\"):\n                os.mkdir(\"checkpoint\")\n                torch.save(state, \"./checkpoint/ckpt.pth\")","metadata":{"execution":{"iopub.status.busy":"2024-04-12T03:03:01.261315Z","iopub.execute_input":"2024-04-12T03:03:01.261691Z","iopub.status.idle":"2024-04-12T03:03:01.272654Z","shell.execute_reply.started":"2024-04-12T03:03:01.261661Z","shell.execute_reply":"2024-04-12T03:03:01.271572Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":" train(\n        model,\n        trainloader,\n        val_loader,\n        epochs,\n        criterion,\n        optimizer,\n        scheduler,\n        early_stopper,\n        device,\n    )","metadata":{"execution":{"iopub.status.busy":"2024-04-12T03:03:04.722322Z","iopub.execute_input":"2024-04-12T03:03:04.722709Z","iopub.status.idle":"2024-04-12T05:14:28.919133Z","shell.execute_reply.started":"2024-04-12T03:03:04.722680Z","shell.execute_reply":"2024-04-12T05:14:28.917756Z"},"trusted":true},"execution_count":19,"outputs":[{"name":"stdout","text":"Epoch 1, Train loss 1.601, Test loss 1.306, Train Accuracy: 0.406, Test Accuracy: 0.537\nEpoch 2, Train loss 1.200, Test loss 1.075, Train Accuracy: 0.567, Test Accuracy: 0.625\nEpoch 3, Train loss 0.999, Test loss 0.900, Train Accuracy: 0.647, Test Accuracy: 0.698\nEpoch 4, Train loss 0.874, Test loss 0.897, Train Accuracy: 0.692, Test Accuracy: 0.705\nEpoch 5, Train loss 0.793, Test loss 0.802, Train Accuracy: 0.723, Test Accuracy: 0.721\nEpoch 6, Train loss 0.715, Test loss 0.640, Train Accuracy: 0.753, Test Accuracy: 0.787\nEpoch 7, Train loss 0.671, Test loss 0.636, Train Accuracy: 0.767, Test Accuracy: 0.792\nEpoch 8, Train loss 0.630, Test loss 0.540, Train Accuracy: 0.780, Test Accuracy: 0.816\nEpoch 9, Train loss 0.590, Test loss 0.551, Train Accuracy: 0.795, Test Accuracy: 0.813\nEpoch 10, Train loss 0.557, Test loss 0.512, Train Accuracy: 0.806, Test Accuracy: 0.824\nEpoch 11, Train loss 0.539, Test loss 0.595, Train Accuracy: 0.813, Test Accuracy: 0.808\nEpoch 12, Train loss 0.518, Test loss 0.457, Train Accuracy: 0.819, Test Accuracy: 0.844\nEpoch 13, Train loss 0.491, Test loss 0.468, Train Accuracy: 0.829, Test Accuracy: 0.846\nEpoch 14, Train loss 0.475, Test loss 0.490, Train Accuracy: 0.834, Test Accuracy: 0.834\nEpoch 15, Train loss 0.465, Test loss 0.463, Train Accuracy: 0.838, Test Accuracy: 0.843\nEpoch 16, Train loss 0.443, Test loss 0.446, Train Accuracy: 0.845, Test Accuracy: 0.850\nEpoch 17, Train loss 0.435, Test loss 0.494, Train Accuracy: 0.850, Test Accuracy: 0.836\nEpoch 18, Train loss 0.415, Test loss 0.417, Train Accuracy: 0.854, Test Accuracy: 0.860\nEpoch 19, Train loss 0.413, Test loss 0.438, Train Accuracy: 0.856, Test Accuracy: 0.858\nEpoch 20, Train loss 0.396, Test loss 0.387, Train Accuracy: 0.861, Test Accuracy: 0.871\nEpoch 21, Train loss 0.384, Test loss 0.537, Train Accuracy: 0.865, Test Accuracy: 0.833\nEpoch 22, Train loss 0.377, Test loss 0.349, Train Accuracy: 0.869, Test Accuracy: 0.882\nEpoch 23, Train loss 0.366, Test loss 0.347, Train Accuracy: 0.873, Test Accuracy: 0.886\nEpoch 24, Train loss 0.356, Test loss 0.370, Train Accuracy: 0.877, Test Accuracy: 0.877\nEpoch 25, Train loss 0.354, Test loss 0.412, Train Accuracy: 0.875, Test Accuracy: 0.868\nEpoch 26, Train loss 0.343, Test loss 0.365, Train Accuracy: 0.880, Test Accuracy: 0.882\nEpoch 27, Train loss 0.334, Test loss 0.367, Train Accuracy: 0.883, Test Accuracy: 0.879\nEpoch 28, Train loss 0.324, Test loss 0.363, Train Accuracy: 0.887, Test Accuracy: 0.884\nEpoch 29, Train loss 0.318, Test loss 0.356, Train Accuracy: 0.890, Test Accuracy: 0.876\nEpoch 30, Train loss 0.311, Test loss 0.357, Train Accuracy: 0.891, Test Accuracy: 0.883\nEpoch 31, Train loss 0.304, Test loss 0.386, Train Accuracy: 0.894, Test Accuracy: 0.874\nEpoch 32, Train loss 0.299, Test loss 0.317, Train Accuracy: 0.896, Test Accuracy: 0.896\nEpoch 33, Train loss 0.294, Test loss 0.330, Train Accuracy: 0.899, Test Accuracy: 0.890\nEpoch 34, Train loss 0.290, Test loss 0.329, Train Accuracy: 0.899, Test Accuracy: 0.892\nEpoch 35, Train loss 0.290, Test loss 0.321, Train Accuracy: 0.898, Test Accuracy: 0.897\nEpoch 36, Train loss 0.279, Test loss 0.331, Train Accuracy: 0.902, Test Accuracy: 0.890\nEpoch 37, Train loss 0.275, Test loss 0.337, Train Accuracy: 0.903, Test Accuracy: 0.892\nEpoch 38, Train loss 0.268, Test loss 0.345, Train Accuracy: 0.908, Test Accuracy: 0.886\nEpoch 39, Train loss 0.272, Test loss 0.345, Train Accuracy: 0.905, Test Accuracy: 0.888\nEpoch 40, Train loss 0.262, Test loss 0.347, Train Accuracy: 0.910, Test Accuracy: 0.890\nEpoch 41, Train loss 0.257, Test loss 0.338, Train Accuracy: 0.910, Test Accuracy: 0.893\nEpoch 42, Train loss 0.258, Test loss 0.323, Train Accuracy: 0.910, Test Accuracy: 0.894\nEpoch 43, Train loss 0.250, Test loss 0.299, Train Accuracy: 0.914, Test Accuracy: 0.903\nEpoch 44, Train loss 0.241, Test loss 0.311, Train Accuracy: 0.914, Test Accuracy: 0.898\nEpoch 45, Train loss 0.240, Test loss 0.310, Train Accuracy: 0.916, Test Accuracy: 0.896\nEpoch 46, Train loss 0.238, Test loss 0.296, Train Accuracy: 0.918, Test Accuracy: 0.904\nEpoch 47, Train loss 0.231, Test loss 0.299, Train Accuracy: 0.920, Test Accuracy: 0.902\nEpoch 48, Train loss 0.228, Test loss 0.336, Train Accuracy: 0.919, Test Accuracy: 0.888\nEpoch 49, Train loss 0.225, Test loss 0.289, Train Accuracy: 0.922, Test Accuracy: 0.904\nEpoch 50, Train loss 0.221, Test loss 0.292, Train Accuracy: 0.923, Test Accuracy: 0.905\nEpoch 51, Train loss 0.226, Test loss 0.324, Train Accuracy: 0.921, Test Accuracy: 0.894\nEpoch 52, Train loss 0.216, Test loss 0.282, Train Accuracy: 0.925, Test Accuracy: 0.907\nEpoch 53, Train loss 0.213, Test loss 0.336, Train Accuracy: 0.926, Test Accuracy: 0.895\nEpoch 54, Train loss 0.216, Test loss 0.304, Train Accuracy: 0.924, Test Accuracy: 0.903\nEpoch 55, Train loss 0.216, Test loss 0.304, Train Accuracy: 0.925, Test Accuracy: 0.903\nEpoch 56, Train loss 0.206, Test loss 0.291, Train Accuracy: 0.927, Test Accuracy: 0.907\nEpoch 57, Train loss 0.206, Test loss 0.280, Train Accuracy: 0.928, Test Accuracy: 0.912\nEpoch 58, Train loss 0.205, Test loss 0.307, Train Accuracy: 0.928, Test Accuracy: 0.903\nEpoch 59, Train loss 0.201, Test loss 0.301, Train Accuracy: 0.929, Test Accuracy: 0.903\nEpoch 60, Train loss 0.191, Test loss 0.334, Train Accuracy: 0.933, Test Accuracy: 0.895\nEpoch 61, Train loss 0.196, Test loss 0.315, Train Accuracy: 0.932, Test Accuracy: 0.902\nEpoch 62, Train loss 0.193, Test loss 0.310, Train Accuracy: 0.932, Test Accuracy: 0.902\nEpoch 63, Train loss 0.190, Test loss 0.299, Train Accuracy: 0.934, Test Accuracy: 0.903\nEpoch 64, Train loss 0.183, Test loss 0.289, Train Accuracy: 0.936, Test Accuracy: 0.909\nEpoch 65, Train loss 0.186, Test loss 0.290, Train Accuracy: 0.935, Test Accuracy: 0.908\nEpoch 66, Train loss 0.180, Test loss 0.316, Train Accuracy: 0.937, Test Accuracy: 0.903\nEpoch 67, Train loss 0.180, Test loss 0.274, Train Accuracy: 0.937, Test Accuracy: 0.913\nEpoch 68, Train loss 0.175, Test loss 0.294, Train Accuracy: 0.939, Test Accuracy: 0.908\nEpoch 69, Train loss 0.179, Test loss 0.287, Train Accuracy: 0.938, Test Accuracy: 0.911\nEpoch 70, Train loss 0.174, Test loss 0.290, Train Accuracy: 0.939, Test Accuracy: 0.913\nEpoch 71, Train loss 0.171, Test loss 0.308, Train Accuracy: 0.939, Test Accuracy: 0.907\nEpoch 72, Train loss 0.170, Test loss 0.278, Train Accuracy: 0.941, Test Accuracy: 0.911\nEpoch 73, Train loss 0.168, Test loss 0.284, Train Accuracy: 0.941, Test Accuracy: 0.913\nEpoch 74, Train loss 0.161, Test loss 0.287, Train Accuracy: 0.944, Test Accuracy: 0.916\nEpoch 75, Train loss 0.166, Test loss 0.288, Train Accuracy: 0.943, Test Accuracy: 0.909\nEpoch 76, Train loss 0.160, Test loss 0.293, Train Accuracy: 0.944, Test Accuracy: 0.907\nEpoch 77, Train loss 0.158, Test loss 0.272, Train Accuracy: 0.945, Test Accuracy: 0.917\nEpoch 78, Train loss 0.157, Test loss 0.264, Train Accuracy: 0.946, Test Accuracy: 0.919\nEpoch 79, Train loss 0.156, Test loss 0.260, Train Accuracy: 0.945, Test Accuracy: 0.922\nEpoch 80, Train loss 0.155, Test loss 0.280, Train Accuracy: 0.946, Test Accuracy: 0.914\nEpoch 81, Train loss 0.150, Test loss 0.273, Train Accuracy: 0.947, Test Accuracy: 0.917\nEpoch 82, Train loss 0.150, Test loss 0.274, Train Accuracy: 0.948, Test Accuracy: 0.915\nEpoch 83, Train loss 0.149, Test loss 0.298, Train Accuracy: 0.947, Test Accuracy: 0.909\nEpoch 84, Train loss 0.142, Test loss 0.272, Train Accuracy: 0.951, Test Accuracy: 0.917\nEpoch 85, Train loss 0.142, Test loss 0.265, Train Accuracy: 0.950, Test Accuracy: 0.918\nEpoch 86, Train loss 0.139, Test loss 0.282, Train Accuracy: 0.953, Test Accuracy: 0.914\nEpoch 87, Train loss 0.138, Test loss 0.285, Train Accuracy: 0.952, Test Accuracy: 0.913\nEpoch 88, Train loss 0.135, Test loss 0.288, Train Accuracy: 0.953, Test Accuracy: 0.910\nEpoch 89, Train loss 0.132, Test loss 0.301, Train Accuracy: 0.955, Test Accuracy: 0.909\nEpoch 90, Train loss 0.136, Test loss 0.281, Train Accuracy: 0.954, Test Accuracy: 0.916\nEpoch 91, Train loss 0.131, Test loss 0.277, Train Accuracy: 0.955, Test Accuracy: 0.914\nEpoch 92, Train loss 0.132, Test loss 0.277, Train Accuracy: 0.955, Test Accuracy: 0.915\nEpoch 93, Train loss 0.125, Test loss 0.287, Train Accuracy: 0.956, Test Accuracy: 0.915\nEpoch 94, Train loss 0.125, Test loss 0.265, Train Accuracy: 0.957, Test Accuracy: 0.919\nEpoch 95, Train loss 0.126, Test loss 0.275, Train Accuracy: 0.955, Test Accuracy: 0.917\nEpoch 96, Train loss 0.125, Test loss 0.292, Train Accuracy: 0.957, Test Accuracy: 0.911\nEpoch 97, Train loss 0.121, Test loss 0.278, Train Accuracy: 0.958, Test Accuracy: 0.916\nEpoch 98, Train loss 0.116, Test loss 0.266, Train Accuracy: 0.959, Test Accuracy: 0.920\nEpoch 99, Train loss 0.116, Test loss 0.264, Train Accuracy: 0.960, Test Accuracy: 0.918\nEpoch 100, Train loss 0.115, Test loss 0.284, Train Accuracy: 0.961, Test Accuracy: 0.916\nEpoch 101, Train loss 0.115, Test loss 0.272, Train Accuracy: 0.960, Test Accuracy: 0.918\nEpoch 102, Train loss 0.108, Test loss 0.272, Train Accuracy: 0.962, Test Accuracy: 0.918\nEpoch 103, Train loss 0.107, Test loss 0.284, Train Accuracy: 0.963, Test Accuracy: 0.919\nEpoch 104, Train loss 0.109, Test loss 0.268, Train Accuracy: 0.963, Test Accuracy: 0.921\nEpoch 105, Train loss 0.109, Test loss 0.265, Train Accuracy: 0.962, Test Accuracy: 0.922\nEpoch 106, Train loss 0.106, Test loss 0.281, Train Accuracy: 0.964, Test Accuracy: 0.920\nEpoch 107, Train loss 0.103, Test loss 0.271, Train Accuracy: 0.965, Test Accuracy: 0.920\nEpoch 108, Train loss 0.097, Test loss 0.284, Train Accuracy: 0.967, Test Accuracy: 0.923\nEpoch 109, Train loss 0.098, Test loss 0.285, Train Accuracy: 0.966, Test Accuracy: 0.917\nEpoch 110, Train loss 0.099, Test loss 0.269, Train Accuracy: 0.966, Test Accuracy: 0.921\nEpoch 111, Train loss 0.095, Test loss 0.259, Train Accuracy: 0.968, Test Accuracy: 0.923\nEpoch 112, Train loss 0.090, Test loss 0.260, Train Accuracy: 0.969, Test Accuracy: 0.924\nEpoch 113, Train loss 0.092, Test loss 0.267, Train Accuracy: 0.968, Test Accuracy: 0.920\nEpoch 114, Train loss 0.092, Test loss 0.265, Train Accuracy: 0.969, Test Accuracy: 0.924\nEpoch 115, Train loss 0.091, Test loss 0.267, Train Accuracy: 0.969, Test Accuracy: 0.923\nEpoch 116, Train loss 0.088, Test loss 0.269, Train Accuracy: 0.971, Test Accuracy: 0.923\nEpoch 117, Train loss 0.085, Test loss 0.259, Train Accuracy: 0.972, Test Accuracy: 0.927\nEpoch 118, Train loss 0.083, Test loss 0.263, Train Accuracy: 0.972, Test Accuracy: 0.925\nEpoch 119, Train loss 0.081, Test loss 0.264, Train Accuracy: 0.973, Test Accuracy: 0.924\nEpoch 120, Train loss 0.084, Test loss 0.276, Train Accuracy: 0.971, Test Accuracy: 0.921\nEpoch 121, Train loss 0.079, Test loss 0.264, Train Accuracy: 0.973, Test Accuracy: 0.924\nEpoch 122, Train loss 0.073, Test loss 0.258, Train Accuracy: 0.975, Test Accuracy: 0.925\nEpoch 123, Train loss 0.073, Test loss 0.253, Train Accuracy: 0.976, Test Accuracy: 0.928\nEpoch 124, Train loss 0.074, Test loss 0.262, Train Accuracy: 0.974, Test Accuracy: 0.925\nEpoch 125, Train loss 0.073, Test loss 0.252, Train Accuracy: 0.975, Test Accuracy: 0.929\nEpoch 126, Train loss 0.069, Test loss 0.258, Train Accuracy: 0.976, Test Accuracy: 0.929\nEpoch 127, Train loss 0.065, Test loss 0.255, Train Accuracy: 0.978, Test Accuracy: 0.926\nEpoch 128, Train loss 0.068, Test loss 0.259, Train Accuracy: 0.977, Test Accuracy: 0.927\nEpoch 129, Train loss 0.061, Test loss 0.257, Train Accuracy: 0.979, Test Accuracy: 0.926\nEpoch 130, Train loss 0.062, Test loss 0.258, Train Accuracy: 0.979, Test Accuracy: 0.927\nEpoch 131, Train loss 0.061, Test loss 0.254, Train Accuracy: 0.979, Test Accuracy: 0.928\nEpoch 132, Train loss 0.064, Test loss 0.264, Train Accuracy: 0.979, Test Accuracy: 0.928\nEpoch 133, Train loss 0.057, Test loss 0.268, Train Accuracy: 0.981, Test Accuracy: 0.924\nEpoch 134, Train loss 0.057, Test loss 0.244, Train Accuracy: 0.980, Test Accuracy: 0.933\nEpoch 135, Train loss 0.055, Test loss 0.246, Train Accuracy: 0.981, Test Accuracy: 0.930\nEpoch 136, Train loss 0.054, Test loss 0.252, Train Accuracy: 0.982, Test Accuracy: 0.931\nEpoch 137, Train loss 0.055, Test loss 0.245, Train Accuracy: 0.982, Test Accuracy: 0.930\nEpoch 138, Train loss 0.049, Test loss 0.245, Train Accuracy: 0.985, Test Accuracy: 0.933\nEpoch 139, Train loss 0.051, Test loss 0.252, Train Accuracy: 0.983, Test Accuracy: 0.932\nEpoch 140, Train loss 0.048, Test loss 0.249, Train Accuracy: 0.984, Test Accuracy: 0.931\nEpoch 141, Train loss 0.046, Test loss 0.250, Train Accuracy: 0.984, Test Accuracy: 0.929\nEpoch 142, Train loss 0.044, Test loss 0.241, Train Accuracy: 0.986, Test Accuracy: 0.934\nEpoch 143, Train loss 0.043, Test loss 0.252, Train Accuracy: 0.986, Test Accuracy: 0.929\nEpoch 144, Train loss 0.042, Test loss 0.248, Train Accuracy: 0.986, Test Accuracy: 0.931\nEpoch 145, Train loss 0.040, Test loss 0.248, Train Accuracy: 0.987, Test Accuracy: 0.932\nEpoch 146, Train loss 0.041, Test loss 0.248, Train Accuracy: 0.987, Test Accuracy: 0.936\nEpoch 147, Train loss 0.038, Test loss 0.251, Train Accuracy: 0.988, Test Accuracy: 0.931\nEpoch 148, Train loss 0.036, Test loss 0.239, Train Accuracy: 0.988, Test Accuracy: 0.935\nEpoch 149, Train loss 0.036, Test loss 0.246, Train Accuracy: 0.989, Test Accuracy: 0.933\nEpoch 150, Train loss 0.035, Test loss 0.244, Train Accuracy: 0.988, Test Accuracy: 0.934\nEpoch 151, Train loss 0.034, Test loss 0.246, Train Accuracy: 0.989, Test Accuracy: 0.934\nEpoch 152, Train loss 0.034, Test loss 0.247, Train Accuracy: 0.989, Test Accuracy: 0.933\nEpoch 153, Train loss 0.033, Test loss 0.248, Train Accuracy: 0.990, Test Accuracy: 0.935\nEpoch 154, Train loss 0.030, Test loss 0.257, Train Accuracy: 0.991, Test Accuracy: 0.931\nEpoch 155, Train loss 0.030, Test loss 0.247, Train Accuracy: 0.991, Test Accuracy: 0.934\nEpoch 156, Train loss 0.028, Test loss 0.246, Train Accuracy: 0.992, Test Accuracy: 0.936\nEpoch 157, Train loss 0.029, Test loss 0.247, Train Accuracy: 0.991, Test Accuracy: 0.935\nEpoch 158, Train loss 0.029, Test loss 0.247, Train Accuracy: 0.991, Test Accuracy: 0.936\nEpoch 159, Train loss 0.026, Test loss 0.245, Train Accuracy: 0.992, Test Accuracy: 0.937\nEpoch 160, Train loss 0.026, Test loss 0.237, Train Accuracy: 0.992, Test Accuracy: 0.940\nEpoch 161, Train loss 0.027, Test loss 0.245, Train Accuracy: 0.991, Test Accuracy: 0.938\nEpoch 162, Train loss 0.026, Test loss 0.242, Train Accuracy: 0.992, Test Accuracy: 0.936\nEpoch 163, Train loss 0.023, Test loss 0.238, Train Accuracy: 0.993, Test Accuracy: 0.937\nEpoch 164, Train loss 0.022, Test loss 0.237, Train Accuracy: 0.993, Test Accuracy: 0.938\nEpoch 165, Train loss 0.022, Test loss 0.237, Train Accuracy: 0.994, Test Accuracy: 0.935\nEpoch 166, Train loss 0.022, Test loss 0.236, Train Accuracy: 0.994, Test Accuracy: 0.938\nEpoch 167, Train loss 0.020, Test loss 0.232, Train Accuracy: 0.994, Test Accuracy: 0.939\nEpoch 168, Train loss 0.019, Test loss 0.236, Train Accuracy: 0.995, Test Accuracy: 0.938\nEpoch 169, Train loss 0.019, Test loss 0.236, Train Accuracy: 0.995, Test Accuracy: 0.937\nEpoch 170, Train loss 0.020, Test loss 0.233, Train Accuracy: 0.994, Test Accuracy: 0.939\nEpoch 171, Train loss 0.018, Test loss 0.236, Train Accuracy: 0.994, Test Accuracy: 0.938\nEpoch 172, Train loss 0.018, Test loss 0.232, Train Accuracy: 0.995, Test Accuracy: 0.939\nEpoch 173, Train loss 0.018, Test loss 0.231, Train Accuracy: 0.995, Test Accuracy: 0.939\nEpoch 174, Train loss 0.019, Test loss 0.235, Train Accuracy: 0.994, Test Accuracy: 0.938\nEpoch 175, Train loss 0.019, Test loss 0.232, Train Accuracy: 0.994, Test Accuracy: 0.937\nEpoch 176, Train loss 0.017, Test loss 0.232, Train Accuracy: 0.995, Test Accuracy: 0.941\nEpoch 177, Train loss 0.016, Test loss 0.231, Train Accuracy: 0.995, Test Accuracy: 0.938\nEpoch 178, Train loss 0.016, Test loss 0.234, Train Accuracy: 0.995, Test Accuracy: 0.937\nEpoch 179, Train loss 0.017, Test loss 0.235, Train Accuracy: 0.995, Test Accuracy: 0.938\nEpoch 180, Train loss 0.016, Test loss 0.236, Train Accuracy: 0.995, Test Accuracy: 0.938\nEpoch 181, Train loss 0.016, Test loss 0.232, Train Accuracy: 0.996, Test Accuracy: 0.940\nEpoch 182, Train loss 0.016, Test loss 0.231, Train Accuracy: 0.995, Test Accuracy: 0.940\nEpoch 183, Train loss 0.016, Test loss 0.232, Train Accuracy: 0.996, Test Accuracy: 0.941\nEpoch 184, Train loss 0.015, Test loss 0.228, Train Accuracy: 0.995, Test Accuracy: 0.941\nEpoch 185, Train loss 0.015, Test loss 0.230, Train Accuracy: 0.996, Test Accuracy: 0.940\nEpoch 186, Train loss 0.016, Test loss 0.233, Train Accuracy: 0.996, Test Accuracy: 0.941\nEpoch 187, Train loss 0.015, Test loss 0.229, Train Accuracy: 0.996, Test Accuracy: 0.941\nEpoch 188, Train loss 0.015, Test loss 0.231, Train Accuracy: 0.996, Test Accuracy: 0.942\nEpoch 189, Train loss 0.014, Test loss 0.228, Train Accuracy: 0.996, Test Accuracy: 0.941\nEpoch 190, Train loss 0.015, Test loss 0.232, Train Accuracy: 0.996, Test Accuracy: 0.939\nEpoch 191, Train loss 0.014, Test loss 0.230, Train Accuracy: 0.996, Test Accuracy: 0.939\nEpoch 192, Train loss 0.015, Test loss 0.233, Train Accuracy: 0.996, Test Accuracy: 0.940\nEpoch 193, Train loss 0.016, Test loss 0.228, Train Accuracy: 0.995, Test Accuracy: 0.940\nEpoch 194, Train loss 0.015, Test loss 0.229, Train Accuracy: 0.996, Test Accuracy: 0.941\nEpoch 195, Train loss 0.015, Test loss 0.230, Train Accuracy: 0.995, Test Accuracy: 0.940\nEpoch 196, Train loss 0.014, Test loss 0.229, Train Accuracy: 0.996, Test Accuracy: 0.939\nEpoch 197, Train loss 0.016, Test loss 0.227, Train Accuracy: 0.995, Test Accuracy: 0.941\nEpoch 198, Train loss 0.015, Test loss 0.231, Train Accuracy: 0.996, Test Accuracy: 0.941\nEpoch 199, Train loss 0.014, Test loss 0.226, Train Accuracy: 0.996, Test Accuracy: 0.942\nEpoch 200, Train loss 0.013, Test loss 0.232, Train Accuracy: 0.997, Test Accuracy: 0.938\n","output_type":"stream"}]},{"cell_type":"code","source":"    valid_loss, valid_correct, valid_total = test(model, val_loader, criterion, device)\n    valid_acc = valid_correct / valid_total\n    print(f\"Valid Accuracy: {valid_acc}\")","metadata":{"execution":{"iopub.status.busy":"2024-04-12T05:14:32.016730Z","iopub.execute_input":"2024-04-12T05:14:32.017473Z","iopub.status.idle":"2024-04-12T05:14:34.459426Z","shell.execute_reply.started":"2024-04-12T05:14:32.017434Z","shell.execute_reply":"2024-04-12T05:14:34.458294Z"},"trusted":true},"execution_count":20,"outputs":[{"name":"stdout","text":"Valid Accuracy: 0.9411\n","output_type":"stream"}]},{"cell_type":"code","source":" train(\n        model,\n        trainloader,\n        val_loader,\n        epochs,\n        criterion,\n        optimizer,\n        scheduler,\n        early_stopper,\n        device,\n    )","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Predict on Custom Test Datataset","metadata":{}},{"cell_type":"code","source":"def infer(model, test_loader, criterion, device):\n    print(len(test_loader))\n    model.eval()\n\n    results = []\n\n    for _, (id_, image) in enumerate(test_loader):\n        image = image.to(device)\n        output = model(image)\n        _, predicted = output.max(1)\n        results.append({\"ID\": id_.item(), \"Labels\": predicted.item()})\n\n    return pd.DataFrame(results)","metadata":{"execution":{"iopub.status.busy":"2024-04-12T05:14:41.152446Z","iopub.execute_input":"2024-04-12T05:14:41.153389Z","iopub.status.idle":"2024-04-12T05:14:41.162197Z","shell.execute_reply.started":"2024-04-12T05:14:41.153339Z","shell.execute_reply":"2024-04-12T05:14:41.161060Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"results = infer(model, testloader, criterion, device)","metadata":{"execution":{"iopub.status.busy":"2024-04-12T05:14:44.176249Z","iopub.execute_input":"2024-04-12T05:14:44.176675Z","iopub.status.idle":"2024-04-12T05:15:30.906487Z","shell.execute_reply.started":"2024-04-12T05:14:44.176621Z","shell.execute_reply":"2024-04-12T05:15:30.905386Z"},"trusted":true},"execution_count":22,"outputs":[{"name":"stdout","text":"10000\n","output_type":"stream"}]},{"cell_type":"code","source":"results.to_csv('/kaggle/working/results.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2024-04-12T05:15:33.461268Z","iopub.execute_input":"2024-04-12T05:15:33.462142Z","iopub.status.idle":"2024-04-12T05:15:33.480275Z","shell.execute_reply.started":"2024-04-12T05:15:33.462108Z","shell.execute_reply":"2024-04-12T05:15:33.479555Z"},"trusted":true},"execution_count":24,"outputs":[]}]}