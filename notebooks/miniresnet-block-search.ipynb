{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Searching for Best Number of Blocks Per Layer\n","\n","After seeing the results of our mofified ResNet with residual blocks [1,1,1,1], we wanted to investigate if we could increase the number of blocks per layer for a noticeable increase in performance. So we trained an additioanl five architectures with the following blocks per layer:  [2,1,1,1], [1,2,1,1], [3,1,1,1], [2,2,1,1], and [1,1,2,1]. Some of these have less than 5M parameters and some have more, but we would have tried other techniques to reduce the number of parameters if the accuracy significantly improved with these mdoels.\n","\n","Ultimately we chose to run further experimentation with [2,1,1,1] since it had less than 5M parameters, had comparable test accuracy to the other highest performing models in this notebook, and it appeared from looking at the loss values that we could continue to train and fine-tune after this initial 30 epochs to continue improving the accuracy."]},{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2024-04-03T20:28:05.266325Z","iopub.status.busy":"2024-04-03T20:28:05.265954Z","iopub.status.idle":"2024-04-03T20:28:23.201364Z","shell.execute_reply":"2024-04-03T20:28:23.200065Z","shell.execute_reply.started":"2024-04-03T20:28:05.266295Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting torchsummary\n","  Downloading torchsummary-1.5.1-py3-none-any.whl.metadata (296 bytes)\n","Downloading torchsummary-1.5.1-py3-none-any.whl (2.8 kB)\n","Installing collected packages: torchsummary\n","Successfully installed torchsummary-1.5.1\n"]}],"source":["!pip install torchsummary"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2024-04-03T20:28:23.203908Z","iopub.status.busy":"2024-04-03T20:28:23.203549Z","iopub.status.idle":"2024-04-03T20:28:37.076031Z","shell.execute_reply":"2024-04-03T20:28:37.075017Z","shell.execute_reply.started":"2024-04-03T20:28:23.203878Z"},"trusted":true},"outputs":[],"source":["import torch\n","import torchvision.transforms as transforms\n","from torchvision import datasets\n","import pickle\n","from PIL import Image\n","import torchsummary\n","import warnings\n","import os\n","import pandas as pd\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","\n"]},{"cell_type":"markdown","metadata":{},"source":["## Load the data"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2024-04-03T20:28:37.077993Z","iopub.status.busy":"2024-04-03T20:28:37.077369Z","iopub.status.idle":"2024-04-03T20:28:37.088719Z","shell.execute_reply":"2024-04-03T20:28:37.087103Z","shell.execute_reply.started":"2024-04-03T20:28:37.077953Z"},"trusted":true},"outputs":[],"source":["class TestData(torch.utils.data.Dataset):\n","    def __init__(self, file_path, transform=None):\n","        self.data = None\n","        with open(file_path, \"rb\") as f:\n","            self.data = pickle.load(f)\n","            self.images = self.data[b\"data\"]\n","            self.ids = self.data[b\"ids\"]\n","        self.transform = transform\n","\n","    def __len__(self):\n","        return len(self.ids)\n","\n","    def __getitem__(self, index):\n","        img = self.images[index]\n","        id_ = self.ids[index]\n","\n","        # Convert image to PIL Image\n","        img = img.reshape(3, 32, 32).transpose(1, 2, 0)\n","        img = Image.fromarray(img)\n","\n","        if self.transform is not None:\n","            img = self.transform(img)\n","\n","        return id_, img\n"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2024-04-03T20:28:37.091901Z","iopub.status.busy":"2024-04-03T20:28:37.091434Z","iopub.status.idle":"2024-04-03T20:28:37.108471Z","shell.execute_reply":"2024-04-03T20:28:37.107364Z","shell.execute_reply.started":"2024-04-03T20:28:37.091862Z"},"trusted":true},"outputs":[],"source":["def augment_data(input_dim=(3, 32, 32)):\n","    transform_train = transforms.Compose(\n","        [\n","            # transforms.RandomVerticalFlip(),\n","            transforms.RandomHorizontalFlip(),\n","            transforms.ColorJitter(\n","                brightness=0.1, contrast=0.1, saturation=0.1, hue=0.1\n","            ),\n","            transforms.RandomCrop(input_dim[1], padding=4),\n","            transforms.ToTensor(),\n","            transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n","        ]\n","    )\n","\n","    transform_val_test = transforms.Compose(\n","        [\n","            transforms.ToTensor(),\n","            transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n","        ]\n","    )\n","    return transform_train, transform_val_test"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2024-04-03T20:28:37.110145Z","iopub.status.busy":"2024-04-03T20:28:37.109712Z","iopub.status.idle":"2024-04-03T20:28:43.725821Z","shell.execute_reply":"2024-04-03T20:28:43.724900Z","shell.execute_reply.started":"2024-04-03T20:28:37.110108Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 170498071/170498071 [00:02<00:00, 84125003.14it/s] \n"]},{"name":"stdout","output_type":"stream","text":["Extracting ./data/cifar-10-python.tar.gz to ./data\n","Files already downloaded and verified\n"]}],"source":["# def load_data(input_dim=(3, 32, 32)):\n","#     import os\n","\n","#     data_directory = os.path.dirname(__file__) + \"/../data\"\n","#     test_path = os.path.join(data_directory, \"testdata\", \"cifar_test_nolabels.pkl\")\n","data_directory = \"./data\"\n","input_dim = (3,32,32)\n","test_path = \"/kaggle/input/test-set/cifar_test_nolabels.pkl\"\n","\n","transform_train, transform_val_test = augment_data(input_dim)\n","\n","trainset = datasets.CIFAR10(\n","    root=data_directory, train=True, download=True, transform=transform_train\n",")\n","trainloader = torch.utils.data.DataLoader(\n","    trainset, batch_size=128, shuffle=True, num_workers=2\n",")\n","\n","val_set = datasets.CIFAR10(\n","    root=data_directory, train=False, download=True, transform=transform_val_test\n",")\n","val_loader = torch.utils.data.DataLoader(\n","    val_set, batch_size=100, shuffle=False, num_workers=2\n",")\n","\n","test_set = TestData(file_path=test_path, transform=transform_val_test)\n","testloader = torch.utils.data.DataLoader(\n","    test_set, batch_size=1, shuffle=False, num_workers=2\n",")\n","\n","classes = (\n","    \"plane\",\n","    \"car\",\n","    \"bird\",\n","    \"cat\",\n","    \"deer\",\n","    \"dog\",\n","    \"frog\",\n","    \"horse\",\n","    \"ship\",\n","    \"truck\",\n",")\n","\n","#     return trainloader, val_loader, testloader, classes\n"]},{"cell_type":"markdown","metadata":{},"source":["# define model"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2024-04-03T20:29:06.242820Z","iopub.status.busy":"2024-04-03T20:29:06.242422Z","iopub.status.idle":"2024-04-03T20:29:06.254170Z","shell.execute_reply":"2024-04-03T20:29:06.252632Z","shell.execute_reply.started":"2024-04-03T20:29:06.242791Z"},"trusted":true},"outputs":[],"source":["class ResidualBlock(nn.Module):\n","    expansion = 1\n","\n","    def __init__(self, in_planes, planes, stride=1):\n","        super(ResidualBlock, self).__init__()\n","        self.conv1 = nn.Conv2d(\n","            in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False\n","        )\n","        self.bn1 = nn.BatchNorm2d(planes)\n","        self.conv2 = nn.Conv2d(\n","            planes, planes, kernel_size=3, stride=1, padding=1, bias=False\n","        )\n","        self.bn2 = nn.BatchNorm2d(planes)\n","\n","        self.shortcut = nn.Sequential()\n","        if stride != 1 or in_planes != self.expansion * planes:\n","            self.shortcut = nn.Sequential(\n","                nn.Conv2d(\n","                    in_planes,\n","                    self.expansion * planes,\n","                    kernel_size=1,\n","                    stride=stride,\n","                    bias=False,\n","                ),\n","                nn.BatchNorm2d(self.expansion * planes),\n","            )\n","\n","    def forward(self, x):\n","        out = F.relu(self.bn1(self.conv1(x)))\n","        out = self.bn2(self.conv2(out))\n","        out += self.shortcut(x)\n","        out = F.relu(out)\n","        return out"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2024-04-03T20:29:08.545741Z","iopub.status.busy":"2024-04-03T20:29:08.545361Z","iopub.status.idle":"2024-04-03T20:29:08.558503Z","shell.execute_reply":"2024-04-03T20:29:08.557340Z","shell.execute_reply.started":"2024-04-03T20:29:08.545713Z"},"trusted":true},"outputs":[],"source":["class MiniResNet(nn.Module):\n","    def __init__(self, num_blocks=(2, 2, 2, 2)):\n","        super(MiniResNet, self).__init__()\n","        self.in_planes = 64\n","\n","        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\n","        self.bn1 = nn.BatchNorm2d(64)\n","        self.layer1 = self._make_layer(64, num_blocks[0], stride=1)\n","        self.layer2 = self._make_layer(128, num_blocks[1], stride=2)\n","        self.layer3 = self._make_layer(256, num_blocks[2], stride=2)\n","        self.layer4 = self._make_layer(512, num_blocks[3], stride=2)\n","        self.linear = nn.Linear(512, 10)\n","#         self.linear = nn.Linear(256, 10)\n","\n","    def _make_layer(self, planes, num_blocks, stride):\n","        strides = [stride] + [1] * (num_blocks - 1)\n","        layers = []\n","        for stride in strides:\n","            layers.append(ResidualBlock(self.in_planes, planes, stride))\n","            self.in_planes = planes\n","        return nn.Sequential(*layers)\n","\n","    def forward(self, x):\n","        out = F.relu(self.bn1(self.conv1(x)))\n","        out = self.layer1(out)\n","        out = self.layer2(out)\n","        out = self.layer3(out)\n","        out = self.layer4(out)\n","        out = F.avg_pool2d(out, 4)\n","        out = out.view(out.size(0), -1)\n","        out = self.linear(out)\n","        return out"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2024-04-03T20:29:10.353143Z","iopub.status.busy":"2024-04-03T20:29:10.352744Z","iopub.status.idle":"2024-04-03T20:29:10.363379Z","shell.execute_reply":"2024-04-03T20:29:10.362223Z","shell.execute_reply.started":"2024-04-03T20:29:10.353114Z"},"trusted":true},"outputs":[],"source":["class EarlyStopper:\n","    def __init__(self, patience=1, min_delta=0):\n","        self.patience = patience\n","        self.min_delta = min_delta\n","        self.counter = 0\n","        self.min_validation_loss = float(\"inf\")\n","\n","    def early_stop(self, validation_loss):\n","        if validation_loss < self.min_validation_loss:\n","            self.min_validation_loss = validation_loss\n","            self.counter = 0\n","        elif validation_loss > (self.min_validation_loss + self.min_delta):\n","            self.counter += 1\n","            if self.counter >= self.patience:\n","                return True\n","        return False\n","\n","\n","def get_optimizers(model):\n","    criterion = nn.CrossEntropyLoss()\n","    optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9, weight_decay=5e-4)\n","    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=200)\n","    early_stopper = EarlyStopper(patience=10, min_delta=10)\n","\n","    return criterion, optimizer, scheduler, early_stopper"]},{"cell_type":"code","execution_count":86,"metadata":{"execution":{"iopub.execute_input":"2024-04-03T22:22:01.605428Z","iopub.status.busy":"2024-04-03T22:22:01.604515Z","iopub.status.idle":"2024-04-03T22:22:01.609997Z","shell.execute_reply":"2024-04-03T22:22:01.609031Z","shell.execute_reply.started":"2024-04-03T22:22:01.605395Z"},"trusted":true},"outputs":[],"source":["def count_parameters(model):\n","    return sum(p.numel() for p in model.parameters() if p.requires_grad)"]},{"cell_type":"markdown","metadata":{},"source":["# Define Train, Test, Infer functions"]},{"cell_type":"code","execution_count":18,"metadata":{"execution":{"iopub.execute_input":"2024-04-03T16:39:32.039611Z","iopub.status.busy":"2024-04-03T16:39:32.038722Z","iopub.status.idle":"2024-04-03T16:39:32.043689Z","shell.execute_reply":"2024-04-03T16:39:32.042834Z","shell.execute_reply.started":"2024-04-03T16:39:32.039579Z"},"trusted":true},"outputs":[],"source":["import torch.backends.cudnn as cudnn\n","\n","device = 'cuda' if torch.cuda.is_available() else 'cpu'"]},{"cell_type":"code","execution_count":25,"metadata":{"execution":{"iopub.execute_input":"2024-04-03T16:47:54.587671Z","iopub.status.busy":"2024-04-03T16:47:54.586643Z","iopub.status.idle":"2024-04-03T16:47:54.593679Z","shell.execute_reply":"2024-04-03T16:47:54.592798Z","shell.execute_reply.started":"2024-04-03T16:47:54.587626Z"},"trusted":true},"outputs":[{"data":{"text/plain":["'cuda'"]},"execution_count":25,"metadata":{},"output_type":"execute_result"}],"source":["device"]},{"cell_type":"code","execution_count":20,"metadata":{"execution":{"iopub.execute_input":"2024-04-03T16:39:35.322554Z","iopub.status.busy":"2024-04-03T16:39:35.321561Z","iopub.status.idle":"2024-04-03T16:39:35.326647Z","shell.execute_reply":"2024-04-03T16:39:35.325660Z","shell.execute_reply.started":"2024-04-03T16:39:35.322519Z"},"trusted":true},"outputs":[],"source":["epochs = 30"]},{"cell_type":"code","execution_count":17,"metadata":{"execution":{"iopub.execute_input":"2024-04-03T20:29:34.436851Z","iopub.status.busy":"2024-04-03T20:29:34.436110Z","iopub.status.idle":"2024-04-03T20:29:34.444066Z","shell.execute_reply":"2024-04-03T20:29:34.443042Z","shell.execute_reply.started":"2024-04-03T20:29:34.436807Z"},"trusted":true},"outputs":[],"source":["def train_epoch(model, train_loader, criterion, optimizer, device):\n","    model.train()\n","    train_loss = 0\n","    correct = 0\n","    total = 0\n","\n","    for _, (inputs, targets) in enumerate(train_loader):\n","        inputs, targets = inputs.to(device), targets.to(device)\n","        optimizer.zero_grad()\n","        outputs = model(inputs)\n","        loss = criterion(outputs, targets)\n","        loss.backward()\n","        optimizer.step()\n","\n","        train_loss += loss.item()\n","        _, predicted = outputs.max(1)\n","        total += targets.size(0)\n","        correct += predicted.eq(targets).sum().item()\n","\n","    return train_loss, correct, total\n"]},{"cell_type":"code","execution_count":22,"metadata":{"execution":{"iopub.execute_input":"2024-04-03T16:39:39.725560Z","iopub.status.busy":"2024-04-03T16:39:39.724822Z","iopub.status.idle":"2024-04-03T16:39:39.734761Z","shell.execute_reply":"2024-04-03T16:39:39.733793Z","shell.execute_reply.started":"2024-04-03T16:39:39.725530Z"},"trusted":true},"outputs":[],"source":["def train(\n","    model,\n","    train_loader,\n","    test_loader,\n","    epochs,\n","    criterion,\n","    optimizer,\n","    scheduler,\n","    early_stopper,\n","    device,\n","):\n","    train_loss_history = []\n","    train_acc_history = []\n","    test_loss_history = []\n","    test_acc_history = []\n","\n","    for epoch in range(epochs):\n","        train_loss, train_correct, train_total = train_epoch(\n","            model, train_loader, criterion, optimizer, device\n","        )\n","        test_loss, test_correct, test_total = test(\n","            model, test_loader, criterion, device\n","        )\n","\n","        train_loss = train_loss / len(train_loader)\n","        test_loss = test_loss / len(test_loader)\n","\n","        train_acc = train_correct / train_total\n","        test_acc = test_correct / test_total\n","\n","        train_loss_history += [train_loss]\n","        test_loss_history += [test_loss]\n","\n","        train_acc_history.append(train_acc)\n","        test_acc_history.append(test_acc)\n","\n","        print(\n","            f\"Epoch {epoch + 1}, Train loss {train_loss:.3f}, Test loss {test_loss:.3f}, Train Accuracy: {train_acc:.3f}, Test Accuracy: {test_acc:.3f}\"\n","        )\n","        scheduler.step()\n","\n","        if (epoch % 10 == 0) or early_stopper.early_stop(test_loss):\n","            state = {\n","                \"epoch\": epoch,\n","                \"state_dict\": model.state_dict(),\n","                \"optimizer_state_dict\": optimizer.state_dict(),\n","                \"loss\": test_loss,\n","            }\n","            if not os.path.isdir(\"checkpoint\"):\n","                os.mkdir(\"checkpoint\")\n","                torch.save(state, \"./checkpoint/ckpt.pth\")"]},{"cell_type":"code","execution_count":18,"metadata":{"execution":{"iopub.execute_input":"2024-04-03T20:29:40.961607Z","iopub.status.busy":"2024-04-03T20:29:40.961200Z","iopub.status.idle":"2024-04-03T20:29:40.969750Z","shell.execute_reply":"2024-04-03T20:29:40.968520Z","shell.execute_reply.started":"2024-04-03T20:29:40.961576Z"},"trusted":true},"outputs":[],"source":["def test(model, test_loader, criterion, device):\n","    model.eval()\n","    test_loss = 0\n","    correct = 0\n","    total = 0\n","\n","    with torch.no_grad():\n","        for _, (inputs, targets) in enumerate(test_loader):\n","            inputs, targets = inputs.to(device), targets.to(device)\n","            outputs = model(inputs)\n","            loss = criterion(outputs, targets)\n","\n","            test_loss += loss.item()\n","            _, predicted = outputs.max(1)\n","            total += targets.size(0)\n","            correct += predicted.eq(targets).sum().item()\n","\n","    return test_loss, correct, total"]},{"cell_type":"code","execution_count":36,"metadata":{"execution":{"iopub.execute_input":"2024-04-03T17:13:05.107979Z","iopub.status.busy":"2024-04-03T17:13:05.107599Z","iopub.status.idle":"2024-04-03T17:13:05.114210Z","shell.execute_reply":"2024-04-03T17:13:05.113247Z","shell.execute_reply.started":"2024-04-03T17:13:05.107949Z"},"trusted":true},"outputs":[],"source":["def infer(model, test_loader, criterion, device):\n","    print(len(test_loader))\n","    model.eval()\n","\n","    results = []\n","\n","    for _, (id_, image) in enumerate(test_loader):\n","        image = image.to(device)\n","        output = model(image)\n","        _, predicted = output.max(1)\n","        results.append({\"ID\": id_.item(), \"Labels\": predicted.item()})\n","\n","    return pd.DataFrame(results)"]},{"cell_type":"markdown","metadata":{},"source":["# Sweep to test different numbers of Residual Blocks per layer"]},{"cell_type":"code","execution_count":47,"metadata":{"execution":{"iopub.execute_input":"2024-04-03T21:27:55.196462Z","iopub.status.busy":"2024-04-03T21:27:55.195780Z","iopub.status.idle":"2024-04-03T21:27:55.202872Z","shell.execute_reply":"2024-04-03T21:27:55.201421Z","shell.execute_reply.started":"2024-04-03T21:27:55.196420Z"},"trusted":true},"outputs":[],"source":["import numpy as np"]},{"cell_type":"code","execution_count":90,"metadata":{"execution":{"iopub.execute_input":"2024-04-03T22:24:10.256452Z","iopub.status.busy":"2024-04-03T22:24:10.255982Z","iopub.status.idle":"2024-04-03T22:24:10.264862Z","shell.execute_reply":"2024-04-03T22:24:10.263670Z","shell.execute_reply.started":"2024-04-03T22:24:10.256419Z"},"trusted":true},"outputs":[{"data":{"text/plain":["5"]},"execution_count":90,"metadata":{},"output_type":"execute_result"}],"source":["num_blocks_list = np.array([[2,1,1,1],[1,2,1,1],[3,1,1,1],[2,2,1,1],[1,1,2,1]])\n","model_names = ['MiniResNet2111','MiniResNet1211','MiniResNet3111','MiniResNet2211','MiniResNet1121']\n","len(num_blocks_list)"]},{"cell_type":"code","execution_count":92,"metadata":{"execution":{"iopub.execute_input":"2024-04-03T22:24:14.059366Z","iopub.status.busy":"2024-04-03T22:24:14.058986Z","iopub.status.idle":"2024-04-03T22:24:14.064859Z","shell.execute_reply":"2024-04-03T22:24:14.063895Z","shell.execute_reply.started":"2024-04-03T22:24:14.059336Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["/kaggle/working/checkpoint/MiniResNet2111ckpt.pth\n","/kaggle/working/checkpoint/MiniResNet1211ckpt.pth\n","/kaggle/working/checkpoint/MiniResNet3111ckpt.pth\n","/kaggle/working/checkpoint/MiniResNet2211ckpt.pth\n","/kaggle/working/checkpoint/MiniResNet1121ckpt.pth\n"]}],"source":["for idx, num_blocks in enumerate(num_blocks_list):\n","    print(\"/kaggle/working/checkpoint/\"+model_names[idx]+\"ckpt.pth\")"]},{"cell_type":"code","execution_count":93,"metadata":{"execution":{"iopub.execute_input":"2024-04-03T22:24:21.302867Z","iopub.status.busy":"2024-04-03T22:24:21.302460Z","iopub.status.idle":"2024-04-03T22:24:21.313570Z","shell.execute_reply":"2024-04-03T22:24:21.312416Z","shell.execute_reply.started":"2024-04-03T22:24:21.302836Z"},"trusted":true},"outputs":[],"source":["def train_logging(\n","    model,\n","    train_loader,\n","    test_loader,\n","    epochs,\n","    criterion,\n","    optimizer,\n","    scheduler,\n","    early_stopper,\n","    device,\n","    model_names\n","):\n","    train_loss_history = []\n","    train_acc_history = []\n","    test_loss_history = []\n","    test_acc_history = []\n","\n","    for epoch in range(epochs):\n","        train_loss, train_correct, train_total = train_epoch(\n","            model, train_loader, criterion, optimizer, device\n","        )\n","        test_loss, test_correct, test_total = test(\n","            model, test_loader, criterion, device\n","        )\n","\n","        train_loss = train_loss / len(train_loader)\n","        test_loss = test_loss / len(test_loader)\n","\n","        train_acc = train_correct / train_total\n","        test_acc = test_correct / test_total\n","\n","        train_loss_history += [train_loss]\n","        test_loss_history += [test_loss]\n","\n","        train_acc_history.append(train_acc)\n","        test_acc_history.append(test_acc)\n","\n","        print(\n","            f\"Epoch {epoch + 1}, Train loss {train_loss:.3f}, Test loss {test_loss:.3f}, Train Accuracy: {train_acc:.3f}, Test Accuracy: {test_acc:.3f}\"\n","        )\n","        scheduler.step()\n","\n","        if (epoch % 10 == 0) or early_stopper.early_stop(test_loss):\n","            state = {\n","                \"epoch\": epoch,\n","                \"state_dict\": model.state_dict(),\n","                \"optimizer_state_dict\": optimizer.state_dict(),\n","                \"loss\": test_loss,\n","            }\n","            if not os.path.isdir(\"checkpoint\"):\n","                os.mkdir(\"checkpoint\")\n","                torch.save(state, \"/kaggle/working/checkpoint/\"+model_names[idx]+\"ckpt.pth\")\n","    return train_loss_history,train_acc_history,test_loss_history,test_acc_history "]},{"cell_type":"code","execution_count":94,"metadata":{"execution":{"iopub.execute_input":"2024-04-03T22:24:23.362461Z","iopub.status.busy":"2024-04-03T22:24:23.361799Z","iopub.status.idle":"2024-04-03T23:58:12.929653Z","shell.execute_reply":"2024-04-03T23:58:12.928339Z","shell.execute_reply.started":"2024-04-03T22:24:23.362427Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Training model with num_blocks=: [2 1 1 1] and total trainable parameters: 4977226 \n","Epoch 1, Train loss 1.475, Test loss 1.410, Train Accuracy: 0.457, Test Accuracy: 0.534\n","Epoch 2, Train loss 1.015, Test loss 1.056, Train Accuracy: 0.638, Test Accuracy: 0.653\n","Epoch 3, Train loss 0.816, Test loss 0.865, Train Accuracy: 0.713, Test Accuracy: 0.708\n","Epoch 4, Train loss 0.692, Test loss 0.752, Train Accuracy: 0.756, Test Accuracy: 0.744\n","Epoch 5, Train loss 0.609, Test loss 0.633, Train Accuracy: 0.788, Test Accuracy: 0.791\n","Epoch 6, Train loss 0.554, Test loss 0.612, Train Accuracy: 0.807, Test Accuracy: 0.803\n","Epoch 7, Train loss 0.508, Test loss 0.632, Train Accuracy: 0.824, Test Accuracy: 0.783\n","Epoch 8, Train loss 0.472, Test loss 0.643, Train Accuracy: 0.835, Test Accuracy: 0.794\n","Epoch 9, Train loss 0.440, Test loss 0.521, Train Accuracy: 0.848, Test Accuracy: 0.825\n","Epoch 10, Train loss 0.417, Test loss 0.498, Train Accuracy: 0.856, Test Accuracy: 0.826\n","Epoch 11, Train loss 0.390, Test loss 0.424, Train Accuracy: 0.866, Test Accuracy: 0.859\n","Epoch 12, Train loss 0.370, Test loss 0.493, Train Accuracy: 0.872, Test Accuracy: 0.837\n","Epoch 13, Train loss 0.348, Test loss 0.512, Train Accuracy: 0.879, Test Accuracy: 0.831\n","Epoch 14, Train loss 0.337, Test loss 0.572, Train Accuracy: 0.882, Test Accuracy: 0.817\n","Epoch 15, Train loss 0.316, Test loss 0.445, Train Accuracy: 0.890, Test Accuracy: 0.857\n","Epoch 16, Train loss 0.301, Test loss 0.417, Train Accuracy: 0.895, Test Accuracy: 0.862\n","Epoch 17, Train loss 0.290, Test loss 0.388, Train Accuracy: 0.900, Test Accuracy: 0.877\n","Epoch 18, Train loss 0.276, Test loss 0.425, Train Accuracy: 0.905, Test Accuracy: 0.863\n","Epoch 19, Train loss 0.267, Test loss 0.394, Train Accuracy: 0.908, Test Accuracy: 0.873\n","Epoch 20, Train loss 0.254, Test loss 0.558, Train Accuracy: 0.913, Test Accuracy: 0.833\n","Epoch 21, Train loss 0.248, Test loss 0.412, Train Accuracy: 0.914, Test Accuracy: 0.877\n","Epoch 22, Train loss 0.238, Test loss 0.414, Train Accuracy: 0.916, Test Accuracy: 0.870\n","Epoch 23, Train loss 0.229, Test loss 0.394, Train Accuracy: 0.920, Test Accuracy: 0.874\n","Epoch 24, Train loss 0.221, Test loss 0.386, Train Accuracy: 0.922, Test Accuracy: 0.879\n","Epoch 25, Train loss 0.211, Test loss 0.357, Train Accuracy: 0.927, Test Accuracy: 0.887\n","Epoch 26, Train loss 0.201, Test loss 0.382, Train Accuracy: 0.931, Test Accuracy: 0.882\n","Epoch 27, Train loss 0.193, Test loss 0.354, Train Accuracy: 0.933, Test Accuracy: 0.889\n","Epoch 28, Train loss 0.189, Test loss 0.395, Train Accuracy: 0.934, Test Accuracy: 0.879\n","Epoch 29, Train loss 0.186, Test loss 0.394, Train Accuracy: 0.935, Test Accuracy: 0.879\n","Epoch 30, Train loss 0.174, Test loss 0.340, Train Accuracy: 0.939, Test Accuracy: 0.893\n","Evaluating final validation accuracy: 0.893\n","Training model with num_blocks=: [1 2 1 1] and total trainable parameters: 5198666 \n","Epoch 1, Train loss 1.473, Test loss 1.573, Train Accuracy: 0.454, Test Accuracy: 0.525\n","Epoch 2, Train loss 1.014, Test loss 0.979, Train Accuracy: 0.640, Test Accuracy: 0.665\n","Epoch 3, Train loss 0.793, Test loss 0.852, Train Accuracy: 0.722, Test Accuracy: 0.718\n","Epoch 4, Train loss 0.677, Test loss 0.672, Train Accuracy: 0.766, Test Accuracy: 0.773\n","Epoch 5, Train loss 0.604, Test loss 0.719, Train Accuracy: 0.791, Test Accuracy: 0.765\n","Epoch 6, Train loss 0.543, Test loss 0.611, Train Accuracy: 0.812, Test Accuracy: 0.792\n","Epoch 7, Train loss 0.495, Test loss 0.552, Train Accuracy: 0.828, Test Accuracy: 0.812\n","Epoch 8, Train loss 0.465, Test loss 0.547, Train Accuracy: 0.838, Test Accuracy: 0.819\n","Epoch 9, Train loss 0.429, Test loss 0.529, Train Accuracy: 0.853, Test Accuracy: 0.826\n","Epoch 10, Train loss 0.404, Test loss 0.452, Train Accuracy: 0.861, Test Accuracy: 0.849\n","Epoch 11, Train loss 0.383, Test loss 0.521, Train Accuracy: 0.868, Test Accuracy: 0.833\n","Epoch 12, Train loss 0.357, Test loss 0.464, Train Accuracy: 0.876, Test Accuracy: 0.852\n","Epoch 13, Train loss 0.341, Test loss 0.622, Train Accuracy: 0.882, Test Accuracy: 0.816\n","Epoch 14, Train loss 0.322, Test loss 0.438, Train Accuracy: 0.888, Test Accuracy: 0.861\n","Epoch 15, Train loss 0.303, Test loss 0.534, Train Accuracy: 0.895, Test Accuracy: 0.835\n","Epoch 16, Train loss 0.289, Test loss 0.419, Train Accuracy: 0.900, Test Accuracy: 0.866\n","Epoch 17, Train loss 0.277, Test loss 0.430, Train Accuracy: 0.904, Test Accuracy: 0.860\n","Epoch 18, Train loss 0.264, Test loss 0.398, Train Accuracy: 0.909, Test Accuracy: 0.875\n","Epoch 19, Train loss 0.253, Test loss 0.392, Train Accuracy: 0.913, Test Accuracy: 0.874\n","Epoch 20, Train loss 0.240, Test loss 0.431, Train Accuracy: 0.916, Test Accuracy: 0.866\n","Epoch 21, Train loss 0.236, Test loss 0.372, Train Accuracy: 0.919, Test Accuracy: 0.879\n","Epoch 22, Train loss 0.222, Test loss 0.362, Train Accuracy: 0.923, Test Accuracy: 0.883\n","Epoch 23, Train loss 0.210, Test loss 0.555, Train Accuracy: 0.926, Test Accuracy: 0.839\n","Epoch 24, Train loss 0.209, Test loss 0.399, Train Accuracy: 0.928, Test Accuracy: 0.876\n","Epoch 25, Train loss 0.196, Test loss 0.377, Train Accuracy: 0.932, Test Accuracy: 0.882\n","Epoch 26, Train loss 0.193, Test loss 0.498, Train Accuracy: 0.932, Test Accuracy: 0.848\n","Epoch 27, Train loss 0.184, Test loss 0.375, Train Accuracy: 0.936, Test Accuracy: 0.881\n","Epoch 28, Train loss 0.178, Test loss 0.367, Train Accuracy: 0.939, Test Accuracy: 0.887\n","Epoch 29, Train loss 0.172, Test loss 0.364, Train Accuracy: 0.940, Test Accuracy: 0.889\n","Epoch 30, Train loss 0.165, Test loss 0.380, Train Accuracy: 0.943, Test Accuracy: 0.886\n","Evaluating final validation accuracy: 0.886\n","Training model with num_blocks=: [3 1 1 1] and total trainable parameters: 5051210 \n","Epoch 1, Train loss 1.492, Test loss 1.341, Train Accuracy: 0.452, Test Accuracy: 0.526\n","Epoch 2, Train loss 1.010, Test loss 1.153, Train Accuracy: 0.640, Test Accuracy: 0.609\n","Epoch 3, Train loss 0.812, Test loss 0.772, Train Accuracy: 0.714, Test Accuracy: 0.746\n","Epoch 4, Train loss 0.688, Test loss 0.668, Train Accuracy: 0.761, Test Accuracy: 0.774\n","Epoch 5, Train loss 0.604, Test loss 0.724, Train Accuracy: 0.789, Test Accuracy: 0.762\n","Epoch 6, Train loss 0.548, Test loss 0.806, Train Accuracy: 0.809, Test Accuracy: 0.739\n","Epoch 7, Train loss 0.502, Test loss 0.562, Train Accuracy: 0.825, Test Accuracy: 0.809\n","Epoch 8, Train loss 0.464, Test loss 0.518, Train Accuracy: 0.840, Test Accuracy: 0.829\n","Epoch 9, Train loss 0.434, Test loss 0.521, Train Accuracy: 0.850, Test Accuracy: 0.827\n","Epoch 10, Train loss 0.407, Test loss 0.512, Train Accuracy: 0.859, Test Accuracy: 0.830\n","Epoch 11, Train loss 0.382, Test loss 0.560, Train Accuracy: 0.868, Test Accuracy: 0.827\n","Epoch 12, Train loss 0.359, Test loss 0.505, Train Accuracy: 0.877, Test Accuracy: 0.841\n","Epoch 13, Train loss 0.339, Test loss 0.510, Train Accuracy: 0.884, Test Accuracy: 0.832\n","Epoch 14, Train loss 0.327, Test loss 0.422, Train Accuracy: 0.888, Test Accuracy: 0.861\n","Epoch 15, Train loss 0.312, Test loss 0.478, Train Accuracy: 0.892, Test Accuracy: 0.845\n","Epoch 16, Train loss 0.297, Test loss 0.475, Train Accuracy: 0.896, Test Accuracy: 0.847\n","Epoch 17, Train loss 0.283, Test loss 0.469, Train Accuracy: 0.902, Test Accuracy: 0.850\n","Epoch 18, Train loss 0.269, Test loss 0.393, Train Accuracy: 0.906, Test Accuracy: 0.872\n","Epoch 19, Train loss 0.262, Test loss 0.445, Train Accuracy: 0.909, Test Accuracy: 0.861\n","Epoch 20, Train loss 0.246, Test loss 0.493, Train Accuracy: 0.915, Test Accuracy: 0.848\n","Epoch 21, Train loss 0.242, Test loss 0.394, Train Accuracy: 0.915, Test Accuracy: 0.871\n","Epoch 22, Train loss 0.233, Test loss 0.447, Train Accuracy: 0.919, Test Accuracy: 0.863\n","Epoch 23, Train loss 0.221, Test loss 0.445, Train Accuracy: 0.924, Test Accuracy: 0.869\n","Epoch 24, Train loss 0.217, Test loss 0.365, Train Accuracy: 0.925, Test Accuracy: 0.883\n","Epoch 25, Train loss 0.207, Test loss 0.341, Train Accuracy: 0.929, Test Accuracy: 0.893\n","Epoch 26, Train loss 0.199, Test loss 0.361, Train Accuracy: 0.930, Test Accuracy: 0.887\n","Epoch 27, Train loss 0.193, Test loss 0.406, Train Accuracy: 0.933, Test Accuracy: 0.872\n","Epoch 28, Train loss 0.184, Test loss 0.394, Train Accuracy: 0.935, Test Accuracy: 0.878\n","Epoch 29, Train loss 0.177, Test loss 0.381, Train Accuracy: 0.939, Test Accuracy: 0.878\n","Epoch 30, Train loss 0.166, Test loss 0.345, Train Accuracy: 0.943, Test Accuracy: 0.892\n","Evaluating final validation accuracy: 0.892\n","Training model with num_blocks=: [2 2 1 1] and total trainable parameters: 5272650 \n","Epoch 1, Train loss 1.447, Test loss 1.244, Train Accuracy: 0.468, Test Accuracy: 0.555\n","Epoch 2, Train loss 0.942, Test loss 1.343, Train Accuracy: 0.665, Test Accuracy: 0.586\n","Epoch 3, Train loss 0.751, Test loss 0.886, Train Accuracy: 0.735, Test Accuracy: 0.711\n","Epoch 4, Train loss 0.641, Test loss 0.722, Train Accuracy: 0.776, Test Accuracy: 0.757\n","Epoch 5, Train loss 0.570, Test loss 0.596, Train Accuracy: 0.801, Test Accuracy: 0.798\n","Epoch 6, Train loss 0.512, Test loss 0.621, Train Accuracy: 0.823, Test Accuracy: 0.802\n","Epoch 7, Train loss 0.472, Test loss 0.570, Train Accuracy: 0.837, Test Accuracy: 0.813\n","Epoch 8, Train loss 0.440, Test loss 0.556, Train Accuracy: 0.849, Test Accuracy: 0.817\n","Epoch 9, Train loss 0.404, Test loss 0.641, Train Accuracy: 0.861, Test Accuracy: 0.795\n","Epoch 10, Train loss 0.383, Test loss 0.494, Train Accuracy: 0.868, Test Accuracy: 0.839\n","Epoch 11, Train loss 0.352, Test loss 0.461, Train Accuracy: 0.878, Test Accuracy: 0.855\n","Epoch 12, Train loss 0.339, Test loss 0.457, Train Accuracy: 0.882, Test Accuracy: 0.856\n","Epoch 13, Train loss 0.318, Test loss 0.489, Train Accuracy: 0.890, Test Accuracy: 0.844\n","Epoch 14, Train loss 0.298, Test loss 0.542, Train Accuracy: 0.897, Test Accuracy: 0.834\n","Epoch 15, Train loss 0.285, Test loss 0.408, Train Accuracy: 0.902, Test Accuracy: 0.864\n","Epoch 16, Train loss 0.272, Test loss 0.397, Train Accuracy: 0.906, Test Accuracy: 0.869\n","Epoch 17, Train loss 0.262, Test loss 0.439, Train Accuracy: 0.909, Test Accuracy: 0.857\n","Epoch 18, Train loss 0.247, Test loss 0.500, Train Accuracy: 0.914, Test Accuracy: 0.838\n","Epoch 19, Train loss 0.238, Test loss 0.457, Train Accuracy: 0.917, Test Accuracy: 0.862\n","Epoch 20, Train loss 0.227, Test loss 0.452, Train Accuracy: 0.922, Test Accuracy: 0.865\n","Epoch 21, Train loss 0.216, Test loss 0.369, Train Accuracy: 0.925, Test Accuracy: 0.883\n","Epoch 22, Train loss 0.207, Test loss 0.375, Train Accuracy: 0.928, Test Accuracy: 0.884\n","Epoch 23, Train loss 0.200, Test loss 0.421, Train Accuracy: 0.931, Test Accuracy: 0.871\n","Epoch 24, Train loss 0.190, Test loss 0.390, Train Accuracy: 0.935, Test Accuracy: 0.884\n","Epoch 25, Train loss 0.187, Test loss 0.360, Train Accuracy: 0.935, Test Accuracy: 0.888\n","Epoch 26, Train loss 0.177, Test loss 0.379, Train Accuracy: 0.938, Test Accuracy: 0.886\n","Epoch 27, Train loss 0.171, Test loss 0.459, Train Accuracy: 0.940, Test Accuracy: 0.862\n","Epoch 28, Train loss 0.165, Test loss 0.332, Train Accuracy: 0.943, Test Accuracy: 0.896\n","Epoch 29, Train loss 0.153, Test loss 0.395, Train Accuracy: 0.947, Test Accuracy: 0.885\n","Epoch 30, Train loss 0.152, Test loss 0.442, Train Accuracy: 0.946, Test Accuracy: 0.867\n","Evaluating final validation accuracy: 0.867\n","Training model with num_blocks=: [1 1 2 1] and total trainable parameters: 6083914 \n","Epoch 1, Train loss 1.461, Test loss 1.205, Train Accuracy: 0.463, Test Accuracy: 0.585\n","Epoch 2, Train loss 0.989, Test loss 1.045, Train Accuracy: 0.647, Test Accuracy: 0.660\n","Epoch 3, Train loss 0.775, Test loss 0.800, Train Accuracy: 0.729, Test Accuracy: 0.725\n","Epoch 4, Train loss 0.659, Test loss 0.673, Train Accuracy: 0.771, Test Accuracy: 0.772\n","Epoch 5, Train loss 0.577, Test loss 0.616, Train Accuracy: 0.799, Test Accuracy: 0.792\n","Epoch 6, Train loss 0.523, Test loss 0.661, Train Accuracy: 0.819, Test Accuracy: 0.780\n","Epoch 7, Train loss 0.479, Test loss 0.531, Train Accuracy: 0.835, Test Accuracy: 0.822\n","Epoch 8, Train loss 0.447, Test loss 0.516, Train Accuracy: 0.846, Test Accuracy: 0.829\n","Epoch 9, Train loss 0.411, Test loss 0.527, Train Accuracy: 0.858, Test Accuracy: 0.826\n","Epoch 10, Train loss 0.382, Test loss 0.495, Train Accuracy: 0.868, Test Accuracy: 0.838\n","Epoch 11, Train loss 0.361, Test loss 0.455, Train Accuracy: 0.875, Test Accuracy: 0.846\n","Epoch 12, Train loss 0.342, Test loss 0.465, Train Accuracy: 0.882, Test Accuracy: 0.845\n","Epoch 13, Train loss 0.322, Test loss 0.407, Train Accuracy: 0.889, Test Accuracy: 0.867\n","Epoch 14, Train loss 0.307, Test loss 0.429, Train Accuracy: 0.894, Test Accuracy: 0.861\n","Epoch 15, Train loss 0.289, Test loss 0.396, Train Accuracy: 0.901, Test Accuracy: 0.869\n","Epoch 16, Train loss 0.274, Test loss 0.403, Train Accuracy: 0.905, Test Accuracy: 0.870\n","Epoch 17, Train loss 0.264, Test loss 0.406, Train Accuracy: 0.908, Test Accuracy: 0.868\n","Epoch 18, Train loss 0.249, Test loss 0.450, Train Accuracy: 0.913, Test Accuracy: 0.862\n","Epoch 19, Train loss 0.234, Test loss 0.409, Train Accuracy: 0.918, Test Accuracy: 0.870\n","Epoch 20, Train loss 0.225, Test loss 0.382, Train Accuracy: 0.921, Test Accuracy: 0.881\n","Epoch 21, Train loss 0.219, Test loss 0.424, Train Accuracy: 0.923, Test Accuracy: 0.872\n","Epoch 22, Train loss 0.205, Test loss 0.364, Train Accuracy: 0.928, Test Accuracy: 0.887\n","Epoch 23, Train loss 0.198, Test loss 0.393, Train Accuracy: 0.930, Test Accuracy: 0.875\n","Epoch 24, Train loss 0.187, Test loss 0.403, Train Accuracy: 0.935, Test Accuracy: 0.876\n","Epoch 25, Train loss 0.179, Test loss 0.343, Train Accuracy: 0.937, Test Accuracy: 0.894\n","Epoch 26, Train loss 0.172, Test loss 0.388, Train Accuracy: 0.940, Test Accuracy: 0.883\n","Epoch 27, Train loss 0.166, Test loss 0.354, Train Accuracy: 0.942, Test Accuracy: 0.893\n","Epoch 28, Train loss 0.156, Test loss 0.330, Train Accuracy: 0.945, Test Accuracy: 0.898\n","Epoch 29, Train loss 0.150, Test loss 0.343, Train Accuracy: 0.948, Test Accuracy: 0.897\n","Epoch 30, Train loss 0.145, Test loss 0.365, Train Accuracy: 0.950, Test Accuracy: 0.895\n","Evaluating final validation accuracy: 0.895\n"]}],"source":["val_accuracy_hist_list = []\n","train_accuracy_hist_list = []\n","val_loss_hist_list = []\n","train_loss_hist_list= []\n","\n","device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","epochs = 30\n","\n","for idx, num_blocks in enumerate(num_blocks_list):\n","    model = MiniResNet(num_blocks=num_blocks).cuda()\n","    criterion, optimizer, scheduler, early_stopper = get_optimizers(model)\n","    num_blocks_string = np.array2string(num_blocks)\n","    \n","    print(\n","            f\"Training model with num_blocks=: {num_blocks_string} and total trainable parameters: {count_parameters(model):d} \"\n","        )\n","    \n","    train_loss_history,train_acc_history,test_loss_history,test_acc_history = train_logging(model,trainloader,\n","                                                                                            val_loader,epochs,criterion,optimizer,\n","                                                                                            scheduler,early_stopper,device,model_names)\n","    \n","    val_accuracy_hist_list.append(test_acc_history)\n","    train_accuracy_hist_list.append(train_acc_history)\n","    val_loss_hist_list.append(test_loss_history)\n","    train_loss_hist_list.append(train_loss_history)\n","    \n","    valid_loss, valid_correct, valid_total = test(model, val_loader, criterion, device)\n","\n","    final_val_acc = valid_correct / valid_total\n","    \n","    print(\n","            f\"Evaluating final validation accuracy: {final_val_acc:.3f}\"\n","        )\n","    "]}],"metadata":{"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"datasetId":4726359,"sourceId":8020904,"sourceType":"datasetVersion"}],"dockerImageVersionId":30674,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat":4,"nbformat_minor":4}
